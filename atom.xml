<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title><![CDATA[Mushroom's blog]]></title>
  <subtitle><![CDATA[没时间玩，就扩大玩的定义，我玩的是技术]]></subtitle>
  <link href="http://lsmushroom.github.io/atom.xml" rel="self"/>
  <link href="http://lsmushroom.github.io"/>
  <updated>2014-04-15T15:37:14.949Z</updated>
  <id>http://lsmushroom.github.io/</id>
  <author>
    <name><![CDATA[Yuan Linsi]]></name>
    <email><![CDATA[lsmushroom@126.com]]></email>
  </author>
  <generator uri="http://zespia.tw/hexo">Hexo</generator>
  <entry>
    <title type="html"><![CDATA[lxc 容器内存使用异常]]></title>
    <link href="http://lsmushroom.github.io/2014/03/17/lxc-容器内存使用异常/"/>
    <id>http://lsmushroom.github.io/2014/03/17/lxc-容器内存使用异常/</id>
    <published>2014-03-17T03:47:07.000Z</published>
    <updated>2014-03-19T08:23:46.000Z</updated>
    <content type="html"><![CDATA[<p>线上机器出现内存泄露，调查过程记录如下。</p>
<a id="more"></a>

<h1 id="malloc_related_function">malloc related function</h1>
<ul>
<li><p>mallopt</p>
<figure class="highlight"><table><tr><td class="gutter"><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
</pre></td><td class="code"><pre><span class="comment">#include &lt;malloc.h&gt;</span>
int mallopt(int param, int value);

- M_MXFAST (<span class="keyword">since</span> glibc <span class="number">2.3</span>)
    
    Set <span class="keyword">the</span> upper limit <span class="keyword">for</span> memory allocation requests <span class="keyword">that</span> are
    satisfied using <span class="string">"fastbins"</span>.  (The measurement unit <span class="keyword">for</span> this
    parameter <span class="keyword">is</span> bytes.)  Fastbins are storage areas <span class="keyword">that</span> hold
    deallocated blocks <span class="keyword">of</span> memory <span class="keyword">of</span> <span class="keyword">the</span> same size <span class="keyword">without</span> merging
    adjacent free blocks.  Subsequent reallocation <span class="keyword">of</span> blocks <span class="keyword">of</span>
    <span class="keyword">the</span> same size can be handled very quickly <span class="keyword">by</span> allocating <span class="keyword">from</span>
    <span class="keyword">the</span> fastbin, although memory fragmentation <span class="keyword">and</span> <span class="keyword">the</span> overall
    memory footprint <span class="keyword">of</span> <span class="keyword">the</span> program can increase.  The default
    value <span class="keyword">for</span> this parameter <span class="keyword">is</span> <span class="number">64</span>*sizeof(size_t)/<span class="number">4</span> (i.e., <span class="number">64</span> <span class="function_start"><span class="keyword">on</span>
    </span><span class="number">32</span>-bit architectures).  The range <span class="keyword">for</span> this parameter <span class="keyword">is</span> <span class="number">0</span> <span class="keyword">to</span>
    <span class="number">80</span>*sizeof(size_t)/<span class="number">4.</span>  Setting M_MXFAST <span class="keyword">to</span> <span class="number">0</span> disables <span class="keyword">the</span> use
    <span class="keyword">of</span> fastbins.

- M_MMAP_THRESHOLD

    For allocations <span class="keyword">greater than</span> <span class="keyword">or</span> <span class="keyword">equal</span> <span class="keyword">to</span> <span class="keyword">the</span> limit specified
    (<span class="keyword">in</span> bytes) <span class="keyword">by</span> M_MMAP_THRESHOLD <span class="keyword">that</span> can <span class="keyword">not</span> be satisfied <span class="keyword">from</span>
    <span class="keyword">the</span> free <span class="type">list</span>, <span class="keyword">the</span> memory-allocation functions employ mmap(<span class="number">2</span>)
    <span class="keyword">instead of</span> increasing <span class="keyword">the</span> program break using sbrk(<span class="number">2</span>).

    Allocating memory using mmap(<span class="number">2</span>) has <span class="keyword">the</span> significant advantage
    <span class="keyword">that</span> <span class="keyword">the</span> allocated memory blocks can always be independently
    released <span class="keyword">back</span> <span class="keyword">to</span> <span class="keyword">the</span> system.  (By contrast, <span class="keyword">the</span> heap can be
        trimmed only <span class="keyword">if</span> memory <span class="keyword">is</span> freed <span class="keyword">at</span> <span class="keyword">the</span> top end.)  On <span class="keyword">the</span> other
    hand, there are <span class="keyword">some</span> disadvantages <span class="keyword">to</span> <span class="keyword">the</span> use <span class="keyword">of</span> mmap(<span class="number">2</span>):
    deallocated <span class="constant">space</span> <span class="keyword">is</span> <span class="keyword">not</span> placed <span class="function_start"><span class="keyword">on</span> <span class="title">the</span></span> free <span class="type">list</span> <span class="keyword">for</span> reuse <span class="keyword">by</span>
    later allocations; memory may be wasted because mmap(<span class="number">2</span>)
    allocations must be page-aligned; <span class="keyword">and</span> <span class="keyword">the</span> kernel must perform
    <span class="keyword">the</span> expensive task <span class="keyword">of</span> zeroing out memory allocated via
    mmap(<span class="number">2</span>).  Balancing these factors leads <span class="keyword">to</span> a default setting
    <span class="keyword">of</span> <span class="number">128</span>*<span class="number">1024</span> <span class="keyword">for</span> <span class="keyword">the</span> M_MMAP_THRESHOLD parameter.

    The lower limit <span class="keyword">for</span> this parameter <span class="keyword">is</span> <span class="number">0.</span>  The upper limit <span class="keyword">is</span>
    DEFAULT_MMAP_THRESHOLD_MAX: <span class="number">512</span>*<span class="number">1024</span> <span class="function_start"><span class="keyword">on</span> </span><span class="number">32</span>-bit systems <span class="keyword">or</span>
    <span class="number">4</span>*<span class="number">1024</span>*<span class="number">1024</span>*sizeof(long) <span class="function_start"><span class="keyword">on</span> </span><span class="number">64</span>-bit systems.

    Note: Nowadays, glibc uses a dynamic mmap threshold <span class="keyword">by</span>
    default.  The initial value <span class="keyword">of</span> <span class="keyword">the</span> threshold <span class="keyword">is</span> <span class="number">128</span>*<span class="number">1024</span>, <span class="keyword">but</span>
    when blocks larger than <span class="keyword">the</span> current threshold <span class="keyword">and</span> <span class="keyword">less than</span> <span class="keyword">or</span>
    <span class="keyword">equal</span> <span class="keyword">to</span> DEFAULT_MMAP_THRESHOLD_MAX are freed, <span class="keyword">the</span> threshold
    <span class="keyword">is</span> adjusted upward <span class="keyword">to</span> <span class="keyword">the</span> size <span class="keyword">of</span> <span class="keyword">the</span> freed block.  When
    dynamic mmap thresholding <span class="keyword">is</span> <span class="keyword">in</span> effect, <span class="keyword">the</span> threshold <span class="keyword">for</span>
    trimming <span class="keyword">the</span> heap <span class="keyword">is</span> also dynamically adjusted <span class="keyword">to</span> be twice <span class="keyword">the</span>
    dynamic mmap threshold.  Dynamic adjustment <span class="keyword">of</span> <span class="keyword">the</span> mmap
    threshold <span class="keyword">is</span> disabled <span class="keyword">if</span> any <span class="keyword">of</span> <span class="keyword">the</span> M_TRIM_THRESHOLD,
    M_TOP_PAD, M_MMAP_THRESHOLD, <span class="keyword">or</span> M_MMAP_MAX parameters <span class="keyword">is</span> set.

- M_TRIM_THRESHOLD
    
    当处于堆顶的连续内存持续增长时，库函数free()将调用sbrk()系统调用
    尝试将这些内存彻底的释放归还给操作系统，这时这些内存才真正的被操
    作系统free的，可为其他进程使用，而在此操作之前，这些内存将被记在
    原进程名下。可通过M_TRIM_THRESHOLD来指定开始回收行为的门槛
    （以字节为单位）。

    默认门槛为<span class="number">128</span>kb，将M_TRIM_THRESHOLD设置为-<span class="number">1</span>将完全关闭回收堆顶内存的
    行为。

    降低M_TRIM_THRESHOLD，将增加系统调用的次数，增大M_TRIM_THRESHOLD
    将浪费处于堆顶的未使用的内存，调整M_TRIM_THRESHOLD需综合考虑。

    When <span class="keyword">the</span> amount <span class="keyword">of</span> contiguous free memory <span class="keyword">at</span> <span class="keyword">the</span> top <span class="keyword">of</span> <span class="keyword">the</span>
    heap grows sufficiently large, free(<span class="number">3</span>) employs sbrk(<span class="number">2</span>) <span class="keyword">to</span>
    release this memory <span class="keyword">back</span> <span class="keyword">to</span> <span class="keyword">the</span> system.  (This can be useful
    <span class="keyword">in</span> programs <span class="keyword">that</span> <span class="keyword">continue</span> <span class="keyword">to</span> execute <span class="keyword">for</span> a long period <span class="keyword">after</span>
    freeing a significant amount <span class="keyword">of</span> memory.)  The M_TRIM_THRESHOLD
    parameter specifies <span class="keyword">the</span> minimum size (<span class="keyword">in</span> bytes) <span class="keyword">that</span> this
    block <span class="keyword">of</span> memory must reach <span class="keyword">before</span> sbrk(<span class="number">2</span>) <span class="keyword">is</span> used <span class="keyword">to</span> trim <span class="keyword">the</span>
    heap.

    The default value <span class="keyword">for</span> this parameter <span class="keyword">is</span> <span class="number">128</span>*<span class="number">1024.</span>  Setting
    M_TRIM_THRESHOLD <span class="keyword">to</span> -<span class="number">1</span> disables trimming completely.

    Modifying M_TRIM_THRESHOLD <span class="keyword">is</span> a trade-off <span class="keyword">between</span> increasing
    <span class="keyword">the</span> <span class="type">number</span> <span class="keyword">of</span> system calls (when <span class="keyword">the</span> parameter <span class="keyword">is</span> <span class="keyword">set</span> low) <span class="keyword">and</span>
    wasting unused memory <span class="keyword">at</span> <span class="keyword">the</span> top <span class="keyword">of</span> <span class="keyword">the</span> heap (when <span class="keyword">the</span>
    parameter <span class="keyword">is</span> <span class="keyword">set</span> high).
</pre></td></tr></table></figure>
</li>
<li><p>mallinfo</p>
<figure class="highlight"><table><tr><td class="gutter"><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
</pre></td><td class="code"><pre><span class="comment">#include &lt;malloc.h&gt;</span>
struct mallinfo mallinfo(void);

struct mallinfo {
    int arena;     /* Non-mmapped <span class="constant">space</span> allocated (bytes) */
    int ordblks;   /* Number <span class="keyword">of</span> free chunks */
    int smblks;    /* Number <span class="keyword">of</span> free fastbin blocks */
    int hblks;     /* Number <span class="keyword">of</span> mmapped regions */
    int hblkhd;    /* Space allocated <span class="keyword">in</span> mmapped regions (bytes) */
    int usmblks;   /* Maximum total allocated <span class="constant">space</span> (bytes) */
    int fsmblks;   /* Space <span class="keyword">in</span> freed fastbin blocks (bytes) */
    int uordblks;  /* Total allocated <span class="constant">space</span> (bytes) */
    int fordblks;  /* Total free <span class="constant">space</span> (bytes) */
    int keepcost;  /* Top-most, releasable <span class="constant">space</span> (bytes) */
};

The fields <span class="keyword">of</span> <span class="keyword">the</span> mallinfo structure <span class="keyword">contain</span> <span class="keyword">the</span> following
information:

arena     当前通过非mmap方式分配的内存块的大小（如处于堆上的内存），包括
          当前在使用以及空闲的（此空闲的部分并未释放回给系统）。
          The total amount <span class="keyword">of</span> memory allocated <span class="keyword">by</span> means other than
          mmap(<span class="number">2</span>) (i.e., memory allocated <span class="function_start"><span class="keyword">on</span> <span class="title">the</span></span> heap).  This figure
          includes both <span class="keyword">in</span>-use blocks <span class="keyword">and</span> blocks <span class="function_start"><span class="keyword">on</span> <span class="title">the</span></span> free list.

ordblks   未处于fastbin中的空闲内存块
          The <span class="type">number</span> <span class="keyword">of</span> ordinary (i.e., non-fastbin) free blocks.

smblks    fastbin 中的空闲块
          The <span class="type">number</span> <span class="keyword">of</span> fastbin free blocks (see mallopt(<span class="number">3</span>)).

hblks     通过mmap分配的内存块
          The <span class="type">number</span> <span class="keyword">of</span> blocks currently allocated using mmap(<span class="number">2</span>).
          (See <span class="keyword">the</span> discussion <span class="keyword">of</span> M_MMAP_THRESHOLD <span class="keyword">in</span> mallopt(<span class="number">3</span>).)

hblkhd    当前通过mmap方式分配的内存的总的字节数
          The <span class="type">number</span> <span class="keyword">of</span> bytes <span class="keyword">in</span> blocks currently allocated using
          mmap(<span class="number">2</span>).

usmblks   
          The <span class="string">"highwater mark"</span> <span class="keyword">for</span> allocated <span class="constant">space</span>—<span class="keyword">that</span> <span class="keyword">is</span>, <span class="keyword">the</span>
          maximum amount <span class="keyword">of</span> <span class="constant">space</span> <span class="keyword">that</span> was ever allocated.  This
          field <span class="keyword">is</span> maintained only <span class="keyword">in</span> nonthreading environments.

fsmblks   当前处于fastbin空闲列表中的内存的总字节数
          The total <span class="type">number</span> <span class="keyword">of</span> bytes <span class="keyword">in</span> fastbin free blocks.

uordblks  The total <span class="type">number</span> <span class="keyword">of</span> bytes used <span class="keyword">by</span> <span class="keyword">in</span>-use allocations.

fordblks  空闲块中的总的字节数
          The total <span class="type">number</span> <span class="keyword">of</span> bytes <span class="keyword">in</span> free blocks.

keepcost  当前堆顶中总的可释放内存空间，此值同时也是
          The total amount <span class="keyword">of</span> releasable free <span class="constant">space</span> <span class="keyword">at</span> <span class="keyword">the</span> top <span class="keyword">of</span> <span class="keyword">the</span>
          heap.  This <span class="keyword">is</span> <span class="keyword">the</span> maximum <span class="type">number</span> <span class="keyword">of</span> bytes <span class="keyword">that</span> could
          ideally (i.e., <span class="keyword">ignoring</span> page alignment restrictions, <span class="keyword">and</span> so
          <span class="function_start"><span class="keyword">on</span></span>) be released <span class="keyword">by</span> malloc_trim(<span class="number">3</span>).
</pre></td></tr></table></figure>

</li>
</ul>
]]></content>
  </entry>
  <entry>
    <title type="html"><![CDATA[namenode-ha]]></title>
    <link href="http://lsmushroom.github.io/2014/03/16/namenode-ha/"/>
    <id>http://lsmushroom.github.io/2014/03/16/namenode-ha/</id>
    <published>2014-03-16T04:03:37.000Z</published>
    <updated>2014-03-16T04:10:58.000Z</updated>
    <content type="html"><![CDATA[<p>实践测试了下hadoop 2.2.0 版本中的NameNode HA特性，记录如下。</p>
<a id="more"></a>

<h1 id="-914d-7f6e-">配置</h1>
<p>开启NameNode HA功能需在hdfs-site.xml与core-site.xml两个文件中添加以下相关的配置项</p>
<p>hdfs-site.xml:</p>
<figure class="highlight"><table><tr><td class="gutter"><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
</pre></td><td class="code"><pre><span class="comment">&lt;!-- Start NameNode HA --&gt;</span>

<span class="tag">&lt;<span class="title">property</span>&gt;</span>
  <span class="tag">&lt;<span class="title">name</span>&gt;</span>dfs.nameservices<span class="tag">&lt;/<span class="title">name</span>&gt;</span>
  <span class="tag">&lt;<span class="title">value</span>&gt;</span>cluster1<span class="tag">&lt;/<span class="title">value</span>&gt;</span>
  <span class="tag">&lt;<span class="title">description</span>&gt;</span>
    Comma-separated list of nameservices.
  <span class="tag">&lt;/<span class="title">description</span>&gt;</span>
<span class="tag">&lt;/<span class="title">property</span>&gt;</span>

<span class="tag">&lt;<span class="title">property</span>&gt;</span>
  <span class="tag">&lt;<span class="title">name</span>&gt;</span>dfs.ha.namenodes.cluster1<span class="tag">&lt;/<span class="title">name</span>&gt;</span>
  <span class="tag">&lt;<span class="title">value</span>&gt;</span>nn1,nn2<span class="tag">&lt;/<span class="title">value</span>&gt;</span>
  <span class="tag">&lt;<span class="title">description</span>&gt;</span>
    命名服务下包含的NameNode列表
    The prefix for a given nameservice, contains a comma-separated
    list of namenodes for a given nameservice (eg EXAMPLENAMESERVICE).
  <span class="tag">&lt;/<span class="title">description</span>&gt;</span>
<span class="tag">&lt;/<span class="title">property</span>&gt;</span>

<span class="tag">&lt;<span class="title">property</span>&gt;</span>
  <span class="tag">&lt;<span class="title">name</span>&gt;</span>dfs.namenode.rpc-address.cluster1.nn1<span class="tag">&lt;/<span class="title">name</span>&gt;</span>
  <span class="tag">&lt;<span class="title">value</span>&gt;</span>master:8020<span class="tag">&lt;/<span class="title">value</span>&gt;</span>
  <span class="tag">&lt;<span class="title">description</span>&gt;</span>
    设置namenode id 对应的RPC端口
    RPC address that handles all clients requests. In the case of HA/Federation where multiple namenodes exist,
    the name service id is added to the name e.g. dfs.namenode.rpc-address.ns1
    dfs.namenode.rpc-address.EXAMPLENAMESERVICE
    The value of this property will take the form of nn-host1:rpc-port.
  <span class="tag">&lt;/<span class="title">description</span>&gt;</span>
<span class="tag">&lt;/<span class="title">property</span>&gt;</span>

<span class="tag">&lt;<span class="title">property</span>&gt;</span>
  <span class="tag">&lt;<span class="title">name</span>&gt;</span>dfs.namenode.rpc-address.cluster1.nn2<span class="tag">&lt;/<span class="title">name</span>&gt;</span>
  <span class="tag">&lt;<span class="title">value</span>&gt;</span>slave0:8020<span class="tag">&lt;/<span class="title">value</span>&gt;</span>
  <span class="tag">&lt;<span class="title">description</span>&gt;</span>
    RPC address that handles all clients requests. In the case of HA/Federation where multiple namenodes exist,
    the name service id is added to the name e.g. dfs.namenode.rpc-address.ns1
    dfs.namenode.rpc-address.EXAMPLENAMESERVICE
    The value of this property will take the form of nn-host1:rpc-port.
  <span class="tag">&lt;/<span class="title">description</span>&gt;</span>
<span class="tag">&lt;/<span class="title">property</span>&gt;</span>

<span class="tag">&lt;<span class="title">property</span>&gt;</span>
  <span class="tag">&lt;<span class="title">name</span>&gt;</span>dfs.namenode.http-address.cluster.nn1<span class="tag">&lt;/<span class="title">name</span>&gt;</span>
  <span class="tag">&lt;<span class="title">value</span>&gt;</span>10.1.93.42:50070<span class="tag">&lt;/<span class="title">value</span>&gt;</span>
  <span class="tag">&lt;<span class="title">description</span>&gt;</span>
    设置每个NameNode对外提供Http服务的端口
    The address and the base port where the dfs namenode web ui will listen on.
  <span class="tag">&lt;/<span class="title">description</span>&gt;</span>
<span class="tag">&lt;/<span class="title">property</span>&gt;</span>

<span class="tag">&lt;<span class="title">property</span>&gt;</span>
  <span class="tag">&lt;<span class="title">name</span>&gt;</span>dfs.namenode.http-address.cluster.nn2<span class="tag">&lt;/<span class="title">name</span>&gt;</span>
  <span class="tag">&lt;<span class="title">value</span>&gt;</span>10.1.93.43:50070<span class="tag">&lt;/<span class="title">value</span>&gt;</span>
  <span class="tag">&lt;<span class="title">description</span>&gt;</span>
    The address and the base port where the dfs namenode web ui will listen on.
  <span class="tag">&lt;/<span class="title">description</span>&gt;</span>
<span class="tag">&lt;/<span class="title">property</span>&gt;</span>

<span class="tag">&lt;<span class="title">property</span>&gt;</span>
  <span class="tag">&lt;<span class="title">name</span>&gt;</span>dfs.namenode.shared.edits.dir<span class="tag">&lt;/<span class="title">name</span>&gt;</span>
  <span class="tag">&lt;<span class="title">value</span>&gt;</span>qjournal://10.1.93.42:8485;10.1.93.43:8485;10.1.93.44:8485/cluster1<span class="tag">&lt;/<span class="title">value</span>&gt;</span>
  <span class="tag">&lt;<span class="title">description</span>&gt;</span>
  提供journal服务的服务器列表,cluster1指定具体的文件夹
  A directory on shared storage between the multiple namenodes
  in an HA cluster. This directory will be written by the active and read
  by the standby in order to keep the namespaces synchronized. This directory
  does not need to be listed in dfs.namenode.edits.dir above. It should be
  left empty in a non-HA cluster.
  <span class="tag">&lt;/<span class="title">description</span>&gt;</span>
<span class="tag">&lt;/<span class="title">property</span>&gt;</span>

<span class="tag">&lt;<span class="title">property</span>&gt;</span>
  <span class="tag">&lt;<span class="title">name</span>&gt;</span>dfs.client.failover.proxy.provider.cluster1<span class="tag">&lt;/<span class="title">name</span>&gt;</span>
  <span class="tag">&lt;<span class="title">value</span>&gt;</span>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider<span class="tag">&lt;/<span class="title">value</span>&gt;</span>
  <span class="tag">&lt;<span class="title">description</span>&gt;</span>
    DFS客户端通过此类查找当前的active NameNode
  <span class="tag">&lt;/<span class="title">description</span>&gt;</span>
<span class="tag">&lt;/<span class="title">property</span>&gt;</span>

<span class="tag">&lt;<span class="title">property</span>&gt;</span>
<span class="tag">&lt;<span class="title">name</span>&gt;</span>dfs.ha.fencing.methods<span class="tag">&lt;/<span class="title">name</span>&gt;</span>
<span class="tag">&lt;<span class="title">value</span>&gt;</span>sshfence<span class="tag">&lt;/<span class="title">value</span>&gt;</span>
<span class="tag">&lt;<span class="title">description</span>&gt;</span>
        状态切换过程中执行的fencing方法，当前提供ssh与shell脚本两种方式,对指定的fencing方法将逐一尝试，直至成功，否则将超时退出
    <span class="tag">&lt;/<span class="title">description</span>&gt;</span>
<span class="tag">&lt;/<span class="title">property</span>&gt;</span>

<span class="tag">&lt;<span class="title">property</span>&gt;</span>
<span class="tag">&lt;<span class="title">name</span>&gt;</span>dfs.ha.fencing.ssh.private-key-files<span class="tag">&lt;/<span class="title">name</span>&gt;</span>
<span class="tag">&lt;<span class="title">value</span>&gt;</span>/opt/home/yuanlinsi/.ssh/id_rsa<span class="tag">&lt;/<span class="title">value</span>&gt;</span>
<span class="tag">&lt;/<span class="title">property</span>&gt;</span>
    
    <span class="tag">&lt;<span class="title">property</span>&gt;</span>
    <span class="tag">&lt;<span class="title">name</span>&gt;</span>dfs.ha.fencing.ssh.connect-timeout<span class="tag">&lt;/<span class="title">name</span>&gt;</span>
    <span class="tag">&lt;<span class="title">value</span>&gt;</span>10000<span class="tag">&lt;/<span class="title">value</span>&gt;</span>
    <span class="tag">&lt;<span class="title">description</span>&gt;</span>以毫秒为单位,默认30000<span class="tag">&lt;/<span class="title">description</span>&gt;</span>
    <span class="tag">&lt;/<span class="title">property</span>&gt;</span>

    <span class="tag">&lt;<span class="title">property</span>&gt;</span>
    <span class="tag">&lt;<span class="title">name</span>&gt;</span>ha.zookeeper.session-timeout.ms<span class="tag">&lt;/<span class="title">name</span>&gt;</span>
    <span class="tag">&lt;<span class="title">value</span>&gt;</span>10000<span class="tag">&lt;/<span class="title">value</span>&gt;</span>
    <span class="tag">&lt;/<span class="title">property</span>&gt;</span>

<span class="tag">&lt;<span class="title">property</span>&gt;</span>
<span class="tag">&lt;<span class="title">name</span>&gt;</span>dfs.journalnode.edits.dir<span class="tag">&lt;/<span class="title">name</span>&gt;</span>
<span class="tag">&lt;<span class="title">value</span>&gt;</span>/opt/linsiyuan/hadoop-journalnode-data<span class="tag">&lt;/<span class="title">value</span>&gt;</span>
<span class="tag">&lt;/<span class="title">property</span>&gt;</span>
</pre></td></tr></table></figure>

<h1 id="-90e8-7f72-">部署</h1>
<h2 id="-542f-52a8-journalnode">启动journalnode</h2>
<p>在dfs.namenode.shared.edits.dir配置项指定的节点上启动journalnode服务，若在所有结点上均启动journalnode，直接通过hadoop-daemons.sh启动，否则需在指定的结点上执行hadoop-daemon.sh来启动journalnode服务</p>
<figure class="highlight"><table><tr><td class="gutter"><pre>1
2
</pre></td><td class="code"><pre><span class="string">.</span><span class="comment">/sbin/hadoop</span><span class="literal">-</span><span class="comment">daemon</span><span class="string">.</span><span class="comment">sh</span> <span class="comment">start</span> <span class="comment">journalnode</span>
<span class="string">.</span><span class="comment">/sbin/hadoop</span><span class="literal">-</span><span class="comment">daemons</span><span class="string">.</span><span class="comment">sh</span> <span class="comment">start</span> <span class="comment">journalnode</span>
</pre></td></tr></table></figure>

<h2 id="-521d-59cb-5316-NameNode">初始化NameNode</h2>
<ul>
<li><p>对于新建立的HDFS集群，需首先在主NameNode上进行格式化操作</p>
<figure class="highlight"><table><tr><td class="gutter"><pre>1
</pre></td><td class="code"><pre><span class="comment">hdfs</span> <span class="comment">namenode</span> <span class="literal">-</span><span class="comment">format</span>
</pre></td></tr></table></figure>
</li>
<li><p>在主NameNode上启动namenode</p>
<figure class="highlight"><table><tr><td class="gutter"><pre>1
2
</pre></td><td class="code"><pre><span class="comment">hdfs</span> <span class="comment">namenode</span> <span class="literal">-</span><span class="comment">initializeSharedEdits</span>
<span class="comment">sbin/hadoop</span><span class="literal">-</span><span class="comment">daemon</span><span class="string">.</span><span class="comment">sh</span> <span class="comment">start</span> <span class="comment">namenode</span>
</pre></td></tr></table></figure>
</li>
<li><p>在从NameNode上启动NameNode,首先通过hdfs namenode -bootstrapStandby 从主NameNode上同步元数据,然后启动namenode</p>
<figure class="highlight"><table><tr><td class="gutter"><pre>1
2
</pre></td><td class="code"><pre><span class="comment">hdfs</span> <span class="comment">namenode</span> <span class="literal">-</span><span class="comment">bootstrapStandby</span>
<span class="string">.</span><span class="comment">/sbin/hadoop</span><span class="literal">-</span><span class="comment">daemon</span><span class="string">.</span><span class="comment">sh</span> <span class="comment">start</span> <span class="comment">namenode</span>
</pre></td></tr></table></figure>
</li>
<li><p>启动所有结点的DataNode</p>
<figure class="highlight"><table><tr><td class="gutter"><pre>1
</pre></td><td class="code"><pre><span class="string">.</span><span class="comment">/sbin/hadoop</span><span class="literal">-</span><span class="comment">daemons</span><span class="string">.</span><span class="comment">sh</span> <span class="comment">start</span> <span class="comment">datanode</span>
</pre></td></tr></table></figure>

</li>
</ul>
<p>切换NameNode的运行状态</p>
<p>在HA模式下，NameNode启动后会直接进入standby模式，可通过以下命令将NameNode切换为active模式</p>
<figure class="highlight"><table><tr><td class="gutter"><pre>1
2
3
4
5
6
7
8
9
10
11
</pre></td><td class="code"><pre> <span class="comment">查询NameNode状态</span>
<span class="string">.</span><span class="comment">/bin/hdfs</span> <span class="comment">haadmin</span> <span class="literal">-</span><span class="comment">getServiceState</span> <span class="comment">nn1</span>
<span class="string">.</span><span class="comment">/bin/hdfs</span> <span class="comment">haadmin</span> <span class="literal">-</span><span class="comment">getServiceState</span> <span class="comment">nn2</span>

 <span class="comment">查询在指定的name</span> <span class="comment">service下，NameNode的状态</span>
<span class="string">.</span><span class="comment">/bin/hdfs</span> <span class="comment">haadmin</span> <span class="literal">-</span><span class="comment">ns</span> <span class="comment">cluster2</span> <span class="literal">-</span><span class="comment">getServiceState</span> <span class="comment">nn1</span>
<span class="string">.</span><span class="comment">/bin/hdfs</span> <span class="comment">haadmin</span> <span class="literal">-</span><span class="comment">ns</span> <span class="comment">cluster2</span> <span class="literal">-</span><span class="comment">getServiceState</span> <span class="comment">nn2</span>

 <span class="comment">在指定的name</span> <span class="comment">service下的切换NameNode的状态</span>
 <span class="string">.</span><span class="comment">/bin/hdfs</span> <span class="comment">haadmin</span> <span class="literal">-</span><span class="comment">ns</span> <span class="title">[</span><span class="comment">name</span> <span class="comment">service</span><span class="title">]</span> <span class="literal">-</span><span class="comment">failover</span> <span class="title">[</span><span class="comment">standby</span><span class="title">]</span> <span class="title">[</span><span class="comment">active</span><span class="title">]</span>
<span class="string">.</span><span class="comment">/bin/hdfs</span> <span class="comment">haadmin</span> <span class="literal">-</span><span class="comment">ns</span> <span class="comment">cluster1</span> <span class="literal">-</span><span class="comment">failover</span> <span class="comment">nn1</span> <span class="comment">nn2</span>
</pre></td></tr></table></figure>

<h1 id="Automatic_Failover">Automatic Failover</h1>
<p>以上方式当处于active模式的NameNode挂掉时需手动进行主备间的状态切换，生产环境显然不现实。hadoop2.2.0 中同样提供基于zookeeper实现的自动切换。</p>
<h2 id="-914d-7f6e--1">配置</h2>
<p>开启自动Failover处理需在以上的配置基础上添加以下的配置项：<br>hdfs-site.xml：</p>
<figure class="highlight"><table><tr><td class="gutter"><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
</pre></td><td class="code"><pre>&lt;<span class="keyword">property</span>&gt;
  &lt;<span class="property">name</span>&gt;dfs.ha.automatic-failover.enabled&lt;/<span class="property">name</span>&gt;
  &lt;value&gt;<span class="constant">true</span>&lt;/value&gt;
  &lt;description&gt;
    Whether automatic failover <span class="keyword">is</span> enabled. See <span class="keyword">the</span> HDFS High
    Availability documentation <span class="keyword">for</span> details <span class="function_start"><span class="keyword">on</span> <span class="title">automatic</span></span> HA
    configuration.
  &lt;/description&gt;
&lt;/<span class="keyword">property</span>&gt;


core-site.xml

&lt;<span class="keyword">property</span>&gt;
  &lt;<span class="property">name</span>&gt;ha.zookeeper.quorum&lt;/<span class="property">name</span>&gt;
  &lt;value&gt;<span class="number">10.1</span><span class="number">.93</span><span class="number">.42</span>:<span class="number">2188</span>,<span class="number">10.1</span><span class="number">.93</span><span class="number">.43</span>:<span class="number">2188</span>,<span class="number">10.1</span><span class="number">.93</span><span class="number">.44</span>:<span class="number">2188</span>&lt;/value&gt;
  &lt;description&gt;
    A <span class="type">list</span> <span class="keyword">of</span> ZooKeeper server addresses, separated <span class="keyword">by</span> commas, <span class="keyword">that</span> are
    <span class="keyword">to</span> be used <span class="keyword">by</span> <span class="keyword">the</span> ZKFailoverController <span class="keyword">in</span> automatic failover.
  &lt;/description&gt;
&lt;/<span class="keyword">property</span>&gt;
</pre></td></tr></table></figure>

<h2 id="-542f-52a8-">启动</h2>
<p>停止集群并添加以上配置项后，可通过以下方式启动集群：</p>
<p>在主NameNode上，启动namenode结点：</p>
<figure class="highlight"><table><tr><td class="gutter"><pre>1
2
3
</pre></td><td class="code"><pre><span class="literal">-</span> <span class="comment">hdfs</span> <span class="comment">namenode</span> <span class="literal">-</span><span class="comment">format</span>
<span class="literal">-</span> <span class="comment">hdfs</span> <span class="comment">namenode</span> <span class="literal">-</span><span class="comment">initializeSharedEdits</span>
<span class="literal">-</span> <span class="comment">sbin/hadoop</span><span class="literal">-</span><span class="comment">daemon</span><span class="string">.</span><span class="comment">sh</span> <span class="comment">start</span> <span class="comment">namenode</span>
</pre></td></tr></table></figure>

<h2 id="-542f-52a8-zkfc-ff1a-">启动zkfc：</h2>
<figure class="highlight"><table><tr><td class="gutter"><pre>1
2
</pre></td><td class="code"><pre><span class="literal">-</span> <span class="comment">hdfs</span> <span class="comment">zkfc</span> <span class="literal">-</span><span class="comment">formatZK</span>
<span class="literal">-</span> <span class="string">.</span><span class="comment">/sbin/hadoop</span><span class="literal">-</span><span class="comment">daemon</span><span class="string">.</span><span class="comment">sh</span> <span class="comment">start</span> <span class="comment">zkfc</span>
</pre></td></tr></table></figure>

<p>在从NameNode上，启动namenode结点：</p>
<figure class="highlight"><table><tr><td class="gutter"><pre>1
2
</pre></td><td class="code"><pre><span class="literal">-</span> <span class="comment">hdfs</span> <span class="comment">namenode</span> <span class="literal">-</span><span class="comment">bootstrapStandby</span>
<span class="literal">-</span> <span class="string">.</span><span class="comment">/sbin/hadoop</span><span class="literal">-</span><span class="comment">daemon</span><span class="string">.</span><span class="comment">sh</span> <span class="comment">start</span> <span class="comment">namenode</span>
</pre></td></tr></table></figure>

<h2 id="-542f-52a8-zkfc-ff1a--1">启动zkfc：</h2>
<figure class="highlight"><table><tr><td class="gutter"><pre>1
</pre></td><td class="code"><pre><span class="literal">-</span> <span class="string">.</span><span class="comment">/sbin/hadoop</span><span class="literal">-</span><span class="comment">daemon</span><span class="string">.</span><span class="comment">sh</span> <span class="comment">start</span> <span class="comment">zkfc</span>
</pre></td></tr></table></figure>

<h2 id="check_NameNode_-72b6-6001-">check NameNode 状态</h2>
<figure class="highlight"><table><tr><td class="gutter"><pre>1
2
</pre></td><td class="code"><pre><span class="comment">hdfs</span> <span class="comment">haadmin</span> <span class="literal">-</span><span class="comment">getServiceState</span> <span class="comment">nn1</span>
<span class="comment">hdfs</span> <span class="comment">haadmin</span> <span class="literal">-</span><span class="comment">getServiceState</span> <span class="comment">nn2</span>
</pre></td></tr></table></figure>

<h2 id="-6d4b-8bd5-">测试</h2>
<p>通过两种方式模拟Namenode异常</p>
<ul>
<li>终止NameNode进程</li>
<li>直接重启active NN </li>
</ul>
<p>两种方式NameNode状态均切换成功，且保持与client及Datanode端的正常通信。</p>
<p>不同之处在于对于直接kill active NameNode，会有zookeeper主动释放锁，而掉电重启active NN所运行的服务器则需等待zookeeper锁超时方能进行Namenode状态切换，由此在掉电的情景中状态切换的过程更长</p>
]]></content>
    <category scheme="http://lsmushroom.github.io/tags/yarn/" term="yarn"/>
  </entry>
  <entry>
    <title type="html"><![CDATA[apache helix 实践]]></title>
    <link href="http://lsmushroom.github.io/2014/02/10/apache-helix-实践/"/>
    <id>http://lsmushroom.github.io/2014/02/10/apache-helix-实践/</id>
    <published>2014-02-10T10:09:08.000Z</published>
    <updated>2014-02-11T08:38:30.000Z</updated>
    <content type="html"><![CDATA[<p>Helix是一个通用的集群管理框架，用于分区，复制和分发托管在一个集群中的节点资源的自动管理。</p>
<a id="more"></a>

<h1 id="Helix_-7279-6027-">Helix 特性</h1>
<p>Helix 提供了以下特性： </p>
<ul>
<li>节点资源的自动分配/分区</li>
<li>节点故障检测和恢复</li>
<li>资源动态增加</li>
<li>集群的动态添加节点</li>
<li>Pluggable distributed state machine to manage the state of a resource via state transitions</li>
<li>自动负载平衡</li>
</ul>
<p>Helix aims to provide the following abilities to a distributed system:</p>
<ul>
<li>Automatic management of a cluster hosting partitioned, replicated resources.</li>
<li>Soft and hard failure detection and handling.</li>
<li>Automatic load balancing via smart placement of resources on servers(nodes) based on server capacity and resource profile (size of partition, access patterns, etc).</li>
<li>Centralized config management and self discovery. Eliminates the need to modify config on each node.</li>
<li>Fault tolerance and optimized rebalancing during cluster expansion.</li>
<li>Manages entire operational lifecycle of a node. Addition, start, stop, enable/disable without downtime.</li>
<li>Monitor cluster health and provide alerts on SLA violation.</li>
<li>Service discovery mechanism to route requests.</li>
</ul>
<h1 id="Helix_Architecture">Helix Architecture</h1>
<p>Helix 作为一套通用的集群管理框架，</p>
<p>Helix 分布式系统的主要组件及属性：</p>
<ul>
<li>结点：实例</li>
<li>资源：Helix 作为一套通用的集群管理框架，可管理多种分布式系统，资源可为数据库，lucense索引或任务等</li>
<li>分区：将全局资源分片为多个分区，Helix管理的对象即为分区</li>
<li>副本：每个分区可有一或多个副本以作冗余</li>
<li>状态: 每个副本均需与特定的状态关联。如：Master, Slave, Leader, Standby, Online, Offline等</li>
</ul>
<p>Helix 集群管理框架中定义了如下三种角色：</p>
<ol>
<li>参与者：集群中实际持有资源的结点</li>
<li>监测者：负责监测参与者结点状态并负责将资源请求发送至适当的参与者</li>
<li><p>控制者：负责全局监测并管理参与者结点。</p>
</li>
<li><p>Participant: The nodes that actually host the distributed resources.</p>
</li>
<li>Spectator: The nodes that simply observe the Participant state and route the request accordingly. Routers, for example, need to know the instance on which a partition is hosted and its state in order to route the request to the appropriate end point.</li>
<li>Controller: The controller observes and controls the Participant nodes. It is responsible for coordinating all transitions in the cluster and ensuring that state constraints are satisfied and cluster stability is maintained. </li>
</ol>
<p>Helix 采用 Zookeeper 来完成集群状态元数据的存储</p>
<p>Helixc 使用一下术语用于描述状态机:</p>
<ul>
<li>IdealState: 理想状态。顾名思义即集群所有节点运行正常，满足所有的状态约束条件。</li>
<li>CurrentState： 当前状态。亦即某个节点运行时的实际状态</li>
<li>ExternalView： 全局视图。即所有节点的当前状态</li>
</ul>
<h1 id="Helix_-5b9e-8df5-">Helix 实践</h1>
<figure class="highlight"><table><tr><td class="gutter"><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
</pre></td><td class="code"><pre>[@<span class="number">10.1</span><span class="number">.41</span><span class="number">.173</span> bin]$ ./quickstart.sh
STARTING Zookeeper <span class="keyword">at</span> localhost:<span class="number">2199</span>
Creating cluster: HELIX_QUICKSTART
Adding <span class="number">2</span> participants <span class="keyword">to</span> <span class="keyword">the</span> cluster
Added participant: localhost_12000
Added participant: localhost_12001
Configuring StateModel: MyStateModel  <span class="keyword">with</span> <span class="number">1</span> Master <span class="keyword">and</span> <span class="number">1</span> Slave
Adding a resource MyResource: <span class="keyword">with</span> <span class="number">6</span> partitions <span class="keyword">and</span> <span class="number">2</span> replicas
Starting Participants
Started Participant: localhost_12000
Started Participant: localhost_12001
Starting Helix Controller
localhost_12001 transitioning <span class="keyword">from</span> OFFLINE <span class="keyword">to</span> SLAVE <span class="keyword">for</span> MyResource_0
localhost_12000 transitioning <span class="keyword">from</span> OFFLINE <span class="keyword">to</span> SLAVE <span class="keyword">for</span> MyResource_0
localhost_12000 transitioning <span class="keyword">from</span> OFFLINE <span class="keyword">to</span> SLAVE <span class="keyword">for</span> MyResource_2
localhost_12001 transitioning <span class="keyword">from</span> OFFLINE <span class="keyword">to</span> SLAVE <span class="keyword">for</span> MyResource_1
localhost_12001 transitioning <span class="keyword">from</span> OFFLINE <span class="keyword">to</span> SLAVE <span class="keyword">for</span> MyResource_2
localhost_12000 transitioning <span class="keyword">from</span> OFFLINE <span class="keyword">to</span> SLAVE <span class="keyword">for</span> MyResource_1
localhost_12000 transitioning <span class="keyword">from</span> OFFLINE <span class="keyword">to</span> SLAVE <span class="keyword">for</span> MyResource_3
localhost_12001 transitioning <span class="keyword">from</span> OFFLINE <span class="keyword">to</span> SLAVE <span class="keyword">for</span> MyResource_4
localhost_12000 transitioning <span class="keyword">from</span> OFFLINE <span class="keyword">to</span> SLAVE <span class="keyword">for</span> MyResource_5
localhost_12001 transitioning <span class="keyword">from</span> OFFLINE <span class="keyword">to</span> SLAVE <span class="keyword">for</span> MyResource_3
localhost_12000 transitioning <span class="keyword">from</span> OFFLINE <span class="keyword">to</span> SLAVE <span class="keyword">for</span> MyResource_4
localhost_12001 transitioning <span class="keyword">from</span> OFFLINE <span class="keyword">to</span> SLAVE <span class="keyword">for</span> MyResource_5
localhost_12000 transitioning <span class="keyword">from</span> SLAVE <span class="keyword">to</span> MASTER <span class="keyword">for</span> MyResource_2
localhost_12000 transitioning <span class="keyword">from</span> SLAVE <span class="keyword">to</span> MASTER <span class="keyword">for</span> MyResource_0
localhost_12000 transitioning <span class="keyword">from</span> SLAVE <span class="keyword">to</span> MASTER <span class="keyword">for</span> MyResource_3
localhost_12001 transitioning <span class="keyword">from</span> SLAVE <span class="keyword">to</span> MASTER <span class="keyword">for</span> MyResource_1
localhost_12001 transitioning <span class="keyword">from</span> SLAVE <span class="keyword">to</span> MASTER <span class="keyword">for</span> MyResource_4
localhost_12001 transitioning <span class="keyword">from</span> SLAVE <span class="keyword">to</span> MASTER <span class="keyword">for</span> MyResource_5
CLUSTER STATE: After starting <span class="number">2</span> nodes
                localhost_12000 localhost_12001
        MyResource_0    M               S
        MyResource_1    S               M
        MyResource_2    M               S
        MyResource_3    M               S
        MyResource_4    S               M
        MyResource_5    S               M
<span class="comment">###################################################################</span>
ADDING NEW NODE :localhost_12002. Partitions will move <span class="keyword">from</span> old nodes <span class="keyword">to</span> <span class="keyword">the</span> new node.
localhost_12001 transitioning <span class="keyword">from</span> MASTER <span class="keyword">to</span> SLAVE <span class="keyword">for</span> MyResource_1
localhost_12000 transitioning <span class="keyword">from</span> MASTER <span class="keyword">to</span> SLAVE <span class="keyword">for</span> MyResource_0
localhost_12001 transitioning <span class="keyword">from</span> MASTER <span class="keyword">to</span> SLAVE <span class="keyword">for</span> MyResource_4
localhost_12000 transitioning <span class="keyword">from</span> MASTER <span class="keyword">to</span> SLAVE <span class="keyword">for</span> MyResource_3
localhost_12001 transitioning <span class="keyword">from</span> SLAVE <span class="keyword">to</span> MASTER <span class="keyword">for</span> MyResource_0
localhost_12000 transitioning <span class="keyword">from</span> SLAVE <span class="keyword">to</span> MASTER <span class="keyword">for</span> MyResource_4
localhost_12002 transitioning <span class="keyword">from</span> OFFLINE <span class="keyword">to</span> SLAVE <span class="keyword">for</span> MyResource_2
localhost_12002 transitioning <span class="keyword">from</span> OFFLINE <span class="keyword">to</span> SLAVE <span class="keyword">for</span> MyResource_1
localhost_12002 transitioning <span class="keyword">from</span> OFFLINE <span class="keyword">to</span> SLAVE <span class="keyword">for</span> MyResource_5
localhost_12002 transitioning <span class="keyword">from</span> OFFLINE <span class="keyword">to</span> SLAVE <span class="keyword">for</span> MyResource_0
localhost_12002 transitioning <span class="keyword">from</span> OFFLINE <span class="keyword">to</span> SLAVE <span class="keyword">for</span> MyResource_3
localhost_12002 transitioning <span class="keyword">from</span> OFFLINE <span class="keyword">to</span> SLAVE <span class="keyword">for</span> MyResource_4
localhost_12002 transitioning <span class="keyword">from</span> SLAVE <span class="keyword">to</span> MASTER <span class="keyword">for</span> MyResource_1
localhost_12002 transitioning <span class="keyword">from</span> SLAVE <span class="keyword">to</span> MASTER <span class="keyword">for</span> MyResource_3
CLUSTER STATE: After adding a <span class="keyword">third</span> node
                localhost_12000 localhost_12001 localhost_12002
        MyResource_0    S               M               S
        MyResource_1    S               S               M
        MyResource_2    M               S               S
        MyResource_3    S               S               M
        MyResource_4    M               S               S
        MyResource_5    S               M               S
<span class="comment">###################################################################</span>
STOPPING localhost_12002. Mastership will be transferred <span class="keyword">to</span> <span class="keyword">the</span> remaining nodes
localhost_12000 transitioning <span class="keyword">from</span> SLAVE <span class="keyword">to</span> MASTER <span class="keyword">for</span> MyResource_1
localhost_12001 transitioning <span class="keyword">from</span> SLAVE <span class="keyword">to</span> MASTER <span class="keyword">for</span> MyResource_3
CLUSTER STATE: After <span class="keyword">the</span> <span class="number">3</span>rd node stops/crashes
                localhost_12000 localhost_12001 localhost_12002
        MyResource_0    S               M               -
        MyResource_1    M               S               -
        MyResource_2    M               S               -
        MyResource_3    S               M               -
        MyResource_4    M               S               -
        MyResource_5    S               M               -
<span class="comment">###################################################################</span>
</pre></td></tr></table></figure>

]]></content>
    <category scheme="http://lsmushroom.github.io/tags/yarn/" term="yarn"/>
    <category scheme="http://lsmushroom.github.io/categories/yarn/" term="yarn"/>
  </entry>
  <entry>
    <title type="html"><![CDATA[idle 进程]]></title>
    <link href="http://lsmushroom.github.io/2014/01/06/top-实现/"/>
    <id>http://lsmushroom.github.io/2014/01/06/top-实现/</id>
    <published>2014-01-06T06:43:18.000Z</published>
    <updated>2014-01-08T14:06:32.000Z</updated>
    <content type="html"><![CDATA[<p>心血来潮分析了下操作系统中的idle进程及动态时钟的相关的实现，简单记录下</p>
<a id="more"></a>

<p>动态时钟是在2.6.17版本中引入内核的，Kernel中与动态时钟相关的配置项为CONFIG_NO_HZ,其设计的初衷就是改变周期性时钟带来的消耗。<br>内核中周期性时钟中断主要用于更新进程时间片进而促发进程调度，也用于更新各个进程运行的统计计数等，而周期性时钟中断的问题在于其触发时钟中断时并不考虑当前系统中进程的运行状况，无论当前系统是空闲的运行的是idle进程还是真正处于繁忙状态都只是定时的周期性的触发时钟中断。</p>
<p>而动态时钟的主要思想是在在系统处于idle状态时主动关闭时钟中断，从而降低时钟中断频率达到减小系统能耗的目的，在有进程需要被调度运行时，将重新开启时钟中断。</p>
<p>但需要注意的是只有经典定时器需要考虑此用法，高分辨率定时器不绑定到时钟频率，也并非基于周期时钟实现。</p>
<p>以下源码为RHEL6 2.6.32版本内核源码的实现，idle进程实为操作系统的0号进程，其在系统启动后首先创建1号init进程，随后便调用cpu_idle()函数使自身成为idle进程，其相关实现如下：</p>
<figure class="highlight"><table><tr><td class="gutter"><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
</pre></td><td class="code"><pre>void cpu_idle(void)
{
	current_thread_info()-&gt;status |= TS_POLLING;

	/*
	 * If we're the non-boot CPU, nothing set the stack canary up
	 * for us.  CPU0 already has it initialized but no harm in
	 * doing it again.  This is a good place for updating it, as
	 * we wont ever return from this function (so the invalid
	 * canaries already on the stack wont ever trigger).
	 */
	boot_init_stack_canary();

	/* endless idle loop with no priority at all */
	while (1) {
        //进入循环后即关闭系统的周期性时钟中断
		tick_nohz_stop_sched_tick(1);
        //退出以下循环的条件为当前系统中有进程需要被调度，否则将进程idle状态
		while (!need_resched()) {

			rmb();

			if (cpu_is_offline(smp_processor_id()))
				play_dead();
			/*
			 * Idle routines should keep interrupts disabled
			 * from here on, until they go to idle.
			 * Otherwise, idle callbacks can misfire.
			 */
			local_irq_disable();
			enter_idle();
			/* Don't trace irqs off for idle */
			stop_critical_timings();
			pm_idle();
			start_critical_timings();
			/* In many cases the interrupt that ended idle
			   has already called exit_idle. But some idle
			   loops can be woken up without interrupt. */
			__exit_idle();
		}

        //当有进程需要调度时，将重新开启周期性时钟中断
		tick_nohz_restart_sched_tick();
		preempt_enable_no_resched();
        //主动触发一次进程调度，当再次回到这里时，说明当前CPU的运行队列为空，idle进程再次被选中运行，进而再次进入循环
		schedule();
		preempt_disable();
	}
}
</pre></td></tr></table></figure>

<p>idle进程的主题逻辑十分清晰，而更让我好奇的是idle进程本身在多核系统启动期间的初始化过程。一番上下求索，逐步清晰其初始化的逻辑：</p>
<p>操作系统启动时将首先启动主CPU，在主CPU上调用start_kernel(),将通过调用sched_init对调度器做初始化,而sched_init()将调用init_idle（）来初始化当前CPU的调度队列的idle,详细如下：</p>
<figure class="highlight"><table><tr><td class="gutter"><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
</pre></td><td class="code"><pre>void __init sched_init(void)
{
    <span class="keyword">...</span>

    init_idle(current, smp_processor_id());

    /*
     * During early bootup we pretend to be a normal task:
     */
    current-&gt;sched_class = &fair_sched_class;

    <span class="keyword">...</span>
}
</pre></td></tr></table></figure>

<figure class="highlight"><table><tr><td class="gutter"><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
</pre></td><td class="code"><pre>void __cpuinit init_idle(struct task_struct <span class="variable">*idle</span>, <span class="keyword">int</span> cpu)
{
	struct rq <span class="variable">*rq</span> = cpu_r<span class="string">q(cpu)</span>;
	unsigned long flags;

	spin_lock_irqsave(&rq-&gt;lock, flags);

	__sched_fork(idle);
	idle-&gt;state = TASK_RUNNING;
	idle-&gt;se.exec_start = sched_clock();

	cpumask_copy(&idle-&gt;cpus_allowed, cpumask_of(cpu));
	__set_task_cpu(idle, cpu);

    <span class="regexp">//</span>在此初始化当前CPU的调度队列的idle进程为当前进程
	rq-&gt;curr = rq-&gt;idle = idle;
<span class="comment">#if defined(CONFIG_SMP) && defined(__ARCH_WANT_UNLOCKED_CTXSW)</span>
	idle-&gt;oncpu = <span class="number">1</span>;
<span class="comment">#endif</span>
	spin_unlock_irqrestore(&rq-&gt;lock, flags);

	<span class="regexp">/* Set the preempt count _outside_ the spinlocks! */</span>
<span class="comment">#if defined(CONFIG_PREEMPT)</span>
	task_thread_info(idle)-&gt;preempt_count = (idle-&gt;lock_depth &gt;= <span class="number">0</span>);
<span class="comment">#else</span>
	task_thread_info(idle)-&gt;preempt_count = <span class="number">0</span>;
<span class="comment">#endif</span>
	/*
	 * The idle tasks have their own, simple scheduling class:
	 <span class="variable">*/</span>
	idle-&gt;sched_class = &idle_sched_class;
	ftrace_graph_init_task(idle);
}
</pre></td></tr></table></figure>

<p>在start_kernel()函数的最后将调用rest_init(),其中在创建完init进程后，将使当前进程进入idle进程的处理逻辑,当系统空闲时当前进程将作为idle进程被调度：</p>
<figure class="highlight"><table><tr><td class="gutter"><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
</pre></td><td class="code"><pre>static noinline void __init_refok rest_init(void)
	__releases(kernel_lock)
{
	int pid;

	rcu_scheduler_starting();
	/*
	 * We need to spawn init first so that it obtains pid-1, however
	 * the init task will end up wanting to create kthreads, which, if
	 * we schedule it before we create kthreadd, will OOPS.
	 */
    //在此创建系统的init进程
	kernel_thread(kernel_init, NULL, CLONE_FS | CLONE_SIGHAND);
	numa_default_policy();
	pid = kernel_thread(kthreadd, NULL, CLONE_FS | CLONE_FILES);
	kthreadd_task = find_task_by_pid_ns(pid, &init_pid_ns);
	complete(&kthreadd_done);
	unlock_kernel();

	/*
	 * The boot idle thread must execute schedule()
	 * at least once to get things moving:
	 */
    //至此，将当前系统启动进程的调度类切换为idle_sched_class调度类,随后让出CPU
	init_idle_bootup_task(current);
	preempt_enable_no_resched();
	schedule();
	preempt_disable();

	/* Call into cpu_idle with preempt disabled */
    //当再次回来时，在完成所有的初始化后将调用cpu_idle()函数，将自身作为主CPU的idle进程运行
	cpu_idle();
}
</pre></td></tr></table></figure>

<p>至此idle进程在主CPU上的初始化过程即完成，当系统空闲时，idle进程如何被选中的呢？<br>以上分析中可知系统的主CPU上的启动进程在最后将自己的调度类切换为idle_sched_class，并在最后调用cpu_idle(),使自身完全进入idle进程的处理逻辑,成为一个普通进程供调度器调度。idle_sched_class定义如下：</p>
<figure class="highlight"><table><tr><td class="gutter"><pre>1
2
3
4
5
6
7
</pre></td><td class="code"><pre>static const struct sched_class idle_sched_class = {
    <span class="keyword">...</span>

	.pick_next_task		= pick_next_task_idle,

    <span class="keyword">...</span>
};
</pre></td></tr></table></figure>

<p>32内核中已引入调度类的概念，在每一次发生进程调度时，将以此遍历各个调度类，需找可被调度需要执行的进程，而idle_sched_class是最后的调度类，当其他的调度类中均没有可被调度的进程时，将由idle_sched_class提供idle进程供调度执行。</p>
<figure class="highlight"><table><tr><td class="gutter"><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
</pre></td><td class="code"><pre><span class="keyword">static</span> inline struct task_struct *
pick_next_task(struct rq *rq)
{
	<span class="keyword">const</span> struct sched_class *<span class="class"><span class="keyword">class</span>;
	<span class="title">struct</span> <span class="title">task_struct</span> *<span class="title">p</span>;

	/*
	 * <span class="title">Optimization</span>: <span class="title">we</span> <span class="title">know</span> <span class="title">that</span> <span class="title">if</span> <span class="title">all</span> <span class="title">tasks</span> <span class="title">are</span> <span class="title">in</span>
	 * <span class="title">the</span> <span class="title">fair</span> <span class="title">class</span> <span class="title">we</span> <span class="title">can</span> <span class="title">call</span> <span class="title">that</span> <span class="title">function</span> <span class="title">directly</span>:
	 */
	<span class="title">if</span> (<span class="title">likely</span>(<span class="title">rq</span>-&gt;<span class="title">nr_running</span> == <span class="title">rq</span>-&gt;<span class="title">cfs</span>.<span class="title">h_nr_running</span>)) {</span>
		p = fair_sched_class.pick_next_task(rq);
		<span class="keyword">if</span> (likely(p))
			<span class="keyword">return</span> p;
	}

    <span class="comment">//循环遍历各个调度类，调用每个调度类定义的pick_next_task()来返回各自调度类中可执行的进程</span>
	for_each_class(<span class="class"><span class="keyword">class</span>) {</span>
		p = <span class="class"><span class="keyword">class</span>-&gt;<span class="title">pick_next_task</span>(<span class="title">rq</span>);
		<span class="title">if</span> (<span class="title">p</span>)
			<span class="title">return</span> <span class="title">p</span>;
	}

	<span class="title">BUG</span>(); /* <span class="title">the</span> <span class="title">idle</span> <span class="title">class</span> <span class="title">will</span> <span class="title">always</span> <span class="title">have</span> <span class="title">a</span> <span class="title">runnable</span> <span class="title">task</span> */
}</span>
</pre></td></tr></table></figure>

<p>pick_next_task_idle的实现如下，简单的返回当前CPU对应的idle进程，而此值是在前文分析的系统启动时被初始化的</p>
<figure class="highlight"><table><tr><td class="gutter"><pre>1
2
3
4
5
6
7
</pre></td><td class="code"><pre><span class="keyword">static</span> <span class="keyword">struct</span> task_struct *pick_next_task_idle(<span class="keyword">struct</span> rq *rq)
{
	schedstat_inc(rq, sched_goidle);
	<span class="comment">/* adjust the active tasks as we might go into a long sleep */</span>
	calc_load_account_active(rq);
	<span class="keyword">return</span> rq-&gt;idle;
}
</pre></td></tr></table></figure>

<p>至此主CPU的idle进程的初始化及被调度的过程分析完毕，但从CPU的初始化过程略有不一样，后续再分析。</p>
<p>Done. ：）</p>
]]></content>
    <category scheme="http://lsmushroom.github.io/tags/kernel/" term="kernel"/>
    <category scheme="http://lsmushroom.github.io/categories/kernel/" term="kernel"/>
  </entry>
  <entry>
    <title type="html"><![CDATA[shell-command-tips]]></title>
    <link href="http://lsmushroom.github.io/2014/01/02/shell-command-tips/"/>
    <id>http://lsmushroom.github.io/2014/01/02/shell-command-tips/</id>
    <published>2014-01-02T13:28:11.000Z</published>
    <updated>2014-04-12T08:28:32.000Z</updated>
    <content type="html"><![CDATA[<p>shell tips<br><a id="more"></a></p>
<ul>
<li><p>execstack</p>
</li>
<li><p>vim 缩进</p>
<figure class="highlight"><table><tr><td class="gutter"><pre>1
2
3
4
5
6
7
8
9
10
11
</pre></td><td class="code"><pre>[vim 自动缩进]http:<span class="regexp">//linux</span>-wiki.cn/wiki/zh-hans/Vim<span class="variable">%E4</span><span class="variable">%BB</span><span class="variable">%A3</span><span class="variable">%E7</span><span class="variable">%A0</span><span class="variable">%81</span><span class="variable">%E7</span><span class="variable">%BC</span><span class="variable">%A9</span><span class="variable">%E8</span><span class="variable">%BF</span><span class="variable">%9B</span><span class="variable">%E8</span><span class="variable">%AE</span><span class="variable">%BE</span><span class="variable">%E7</span><span class="variable">%BD</span><span class="variable">%AE</span>
set ci       <span class="comment"># 开启cindent</span>
set noet     <span class="comment"># 关闭expandtab</span>
set sw=<span class="number">4</span>     <span class="comment"># shiftwidth=4</span>

变量名           缩写    含义
tabstop=X        ts      编辑时一个TAB字符占多少个空格的位置。
shiftwidth=X     sw      使用每层缩进的空格数。
(<span class="keyword">no</span>)expandtab    (<span class="keyword">no</span>)et  是否将输入的TAB自动展开成空格。开启后要输入TAB，需要Ctrl-V&lt;TAB&gt;
softtabstop=X    sts     方便在开启了et后使用退格（backspace）键，每次退格将删除X个空格
(<span class="keyword">no</span>)smarttab     (<span class="keyword">no</span>)sta 开启时，在行首按TAB将加入sw个空格，否则加入ts个空格。
</pre></td></tr></table></figure>
</li>
<li><p>ss<br>ss 是一个查看当前系统中网络连接信息的利器<br>ss -n -e -m -p -i -s</p>
</li>
<li><p>trap:</p>
<figure class="highlight"><table><tr><td class="gutter"><pre>1
2
3
4
5
6
7
</pre></td><td class="code"><pre>trap [-lp] [[arg] sigspec <span class="keyword">...</span>]

arg: 信号处理函数，当接收到有sigspec定义的信号时将触发有args定义的命令的执行

<span class="number">1.</span> 如未指定arg或arg为<span class="string">" - "</span> ， 则当收到sigspec时将信号复位为原值
<span class="number">2.</span> 如arg指定为<span class="literal">NULL</span> ， 则sigspec指定的信号将被当前shell脚本以及触发信号的命令忽略
<span class="number">3.</span> trap -l 列出当前的信号列表
</pre></td></tr></table></figure>
</li>
<li><p>usermod</p>
<figure class="highlight"><table><tr><td class="gutter"><pre>1
2
3
4
5
</pre></td><td class="code"><pre>usermod <span class="attribute">-m</span> <span class="attribute">-d</span> <span class="variable">$NEW_HOME_PATH</span> <span class="variable">$USER</span>
将<span class="variable">$USER</span>指定的用户的home目录切换至新目录中，并将原目录中的文件移动至新目录中

ps <span class="attribute">-U</span> <span class="variable">$USER</span> <span class="attribute">-u</span> <span class="variable">$user</span>
仅显示指定用户的进程，可用于干掉死掉的终端
</pre></td></tr></table></figure>
</li>
<li><p>here document 用法 (cat &lt;&lt; EOF)<br>Here Document 是在Linux Shell 中的一种特殊的重定向方式，它的基本的形式如下</p>
<figure class="highlight"><table><tr><td class="gutter"><pre>1
2
3
</pre></td><td class="code"><pre><span class="title">cmd</span> &lt;&lt; delimiter
<span class="type">Here</span> <span class="type">Document</span> <span class="type">Content</span>
<span class="title">delimiter</span>
</pre></td></tr></table></figure>

</li>
</ul>
<p>它的作用就是将两个 delimiter 之间的内容(Here Document Content 部分) 传递给cmd 作为输入参数，delimiter可自定义，通常可用于在脚本中动态的生成新的脚本。</p>
<p>delimiter间的内容可嵌入变量 ，其值取决于运行时的shell环境，且变量会在shell运行时被展开，重定向时会将展开后的值写入重定向文件</p>
<figure class="highlight"><table><tr><td class="gutter"><pre>1
2
3
4
5
</pre></td><td class="code"><pre>A=test
cat &lt;&lt; EOF &gt; output.sh
<span class="built_in">echo</span> <span class="string">"This is output"</span>
<span class="built_in">echo</span> <span class="variable">$A</span>
EOF
</pre></td></tr></table></figure>

<p>写入output.sh将是test<br>如要禁止变量展开，可以通过在起始的 delimiter的前后添加 “ 来实现，</p>
<figure class="highlight"><table><tr><td class="gutter"><pre>1
2
3
4
5
</pre></td><td class="code"><pre>A=test
cat &lt;&lt; <span class="string">"EOF"</span> &gt; output.sh  <span class="comment">#注意引号</span>
<span class="built_in">echo</span> <span class="string">"hello"</span>
<span class="built_in">echo</span> <span class="variable">$A</span> 
EOF
</pre></td></tr></table></figure>

<p>写入output.sh的将是$A</p>
<p>&lt;&lt; 变为 &lt;&lt;-<br>Here Document 还有一个用法就是将 ‘«’ 变为 ‘«-‘。 使用 &lt;&lt;- 的唯一变化就是Here Document 的内容部分每行前面的 tab (制表符)将会被删除掉，这种用法是为了编写Here Document的时候可以将内容部分进行缩进，方便阅读代码。</p>
<ul>
<li><p>netstat 查看当前打开的端口及对应的进程<br>netstat -nlpt</p>
</li>
<li><p>expect<br>运行autoexpect -p就进入autoexpect创建的shell中，然后输入的命令交互都被记录下来，最后输入exit退出，expect脚本被保存在script.exp中。<br>下面的例子演示了通过ssh登录到一台主机然后退出。</p>
</li>
</ul>
<figure class="highlight"><table><tr><td class="gutter"><pre>1
</pre></td><td class="code"><pre><span class="comment">rong@dev:~＄</span> <span class="comment">autoexpect</span> <span class="literal">-</span><span class="comment">p</span> <span class="comment">ssh</span> <span class="comment">172</span><span class="string">.</span><span class="comment">16</span><span class="string">.</span><span class="comment">24</span><span class="string">.</span><span class="comment">57</span> <span class="literal">-</span><span class="comment">lroot</span> <span class="literal">-</span><span class="comment">p3600</span>
</pre></td></tr></table></figure>

]]></content>
    <category scheme="http://lsmushroom.github.io/tags/shell/" term="shell"/>
  </entry>
  <entry>
    <title type="html"><![CDATA[maven 使用]]></title>
    <link href="http://lsmushroom.github.io/2014/01/02/maven-使用/"/>
    <id>http://lsmushroom.github.io/2014/01/02/maven-使用/</id>
    <published>2014-01-02T12:27:46.000Z</published>
    <updated>2014-03-16T04:12:29.000Z</updated>
    <content type="html"><![CDATA[<p>学习下maven 使用<br><a id="more"></a></p>
<ul>
<li>创建项目<figure class="highlight"><table><tr><td class="gutter"><pre>1
</pre></td><td class="code"><pre>mvn archetype:create -DgroupId=<span class="keyword">com</span><span class="preprocessor">.practise</span><span class="preprocessor">.java</span> -DartifactId=helloworld -DpackageName=<span class="keyword">com</span><span class="preprocessor">.practise</span><span class="preprocessor">.java</span>
</pre></td></tr></table></figure>

</li>
</ul>
<p>创建后的目录结构如下:</p>
<figure class="highlight"><table><tr><td class="gutter"><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
</pre></td><td class="code"><pre>[@sohu_41_173 java-practise]$ tree helloworld/
helloworld/
├── pom<span class="preprocessor">.xml</span>
└── src
    ├── main
    │   └── java
    │       └── <span class="keyword">com</span>
    │           └── practise
    │               └── java
    │                   └── App<span class="preprocessor">.java</span>
    └── test
        └── java
            └── <span class="keyword">com</span>
                └── practise
                    └── java
                        └── AppTest<span class="preprocessor">.java</span>

<span class="number">11</span> directories, <span class="number">3</span> files
</pre></td></tr></table></figure>

<p>其中archetype:create称为一个Maven目标，archetype是一个插件标识而create是目标标识,相应的会创建一个pom.xml文件，文件中各项的含义如下：</p>
<figure class="highlight"><table><tr><td class="gutter"><pre>1
2
3
4
5
6
</pre></td><td class="code"><pre><span class="literal">-</span> <span class="comment">groupId:</span> <span class="comment">通常为项目的顶级包名。</span>
<span class="literal">-</span> <span class="comment">artifactId:</span> <span class="comment">通常为项目名</span>
<span class="literal">-</span> <span class="comment">version：项目的版本号，在开发的不同阶段，你需要更改这个版本号。</span>
<span class="literal">-</span> <span class="comment">packaging：项目发布时的打包类型。比如对于普通Java程序打包为jar文件；对于Java</span> <span class="comment">web项目则打包为war文件。</span>
<span class="literal">-</span> <span class="comment">name：通常也是项目名</span>
<span class="literal">-</span> <span class="comment">url：项目的主页。</span>
</pre></td></tr></table></figure>

<ul>
<li>安装<figure class="highlight"><table><tr><td class="gutter"><pre>1
</pre></td><td class="code"><pre><span class="title">mvn</span> clean install
</pre></td></tr></table></figure>

</li>
</ul>
<p>会将由mvn package编译生成的jar包拷贝至类似如下的路径：</p>
<figure class="highlight"><table><tr><td class="gutter"><pre>1
</pre></td><td class="code"><pre><span class="comment">/opt/home/mushroom/</span><span class="string">.</span><span class="comment">m2/repository/com/practise/java/helloworld/1</span><span class="string">.</span><span class="comment">0</span><span class="literal">-</span><span class="comment">SNAPSHOT/helloworld</span><span class="literal">-</span><span class="comment">1</span><span class="string">.</span><span class="comment">0</span><span class="literal">-</span><span class="comment">SNAPSHOT</span><span class="string">.</span><span class="comment">jar</span>
</pre></td></tr></table></figure>

<ul>
<li><p>清理</p>
<figure class="highlight"><table><tr><td class="gutter"><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
</pre></td><td class="code"><pre><span class="title">[</span><span class="comment">@sohu_41_173</span> <span class="comment">helloworld</span><span class="title">]</span><span class="comment">$</span> <span class="comment">mvn</span> <span class="comment">clean</span>
<span class="title">[</span><span class="comment">INFO</span><span class="title">]</span> <span class="comment">Scanning</span> <span class="comment">for</span> <span class="comment">projects</span><span class="string">.</span><span class="string">.</span><span class="string">.</span>
<span class="title">[</span><span class="comment">INFO</span><span class="title">]</span>
<span class="title">[</span><span class="comment">INFO</span><span class="title">]</span> <span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span>
<span class="title">[</span><span class="comment">INFO</span><span class="title">]</span> <span class="comment">Building</span> <span class="comment">helloworld</span> <span class="comment">1</span><span class="string">.</span><span class="comment">0</span><span class="literal">-</span><span class="comment">SNAPSHOT</span>
<span class="title">[</span><span class="comment">INFO</span><span class="title">]</span> <span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span>
<span class="title">[</span><span class="comment">INFO</span><span class="title">]</span>
<span class="title">[</span><span class="comment">INFO</span><span class="title">]</span> <span class="literal">-</span><span class="literal">-</span><span class="literal">-</span> <span class="comment">maven</span><span class="literal">-</span><span class="comment">clean</span><span class="literal">-</span><span class="comment">plugin:2</span><span class="string">.</span><span class="comment">5:clean</span> <span class="comment">(default</span><span class="literal">-</span><span class="comment">clean)</span> <span class="comment">@</span> <span class="comment">helloworld</span> <span class="literal">-</span><span class="literal">-</span><span class="literal">-</span>
<span class="title">[</span><span class="comment">INFO</span><span class="title">]</span> <span class="comment">Deleting</span> <span class="comment">/opt/linsiyuan/git/java</span><span class="literal">-</span><span class="comment">practise/helloworld/target</span>
<span class="title">[</span><span class="comment">INFO</span><span class="title">]</span> <span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span>
<span class="title">[</span><span class="comment">INFO</span><span class="title">]</span> <span class="comment">BUILD</span> <span class="comment">SUCCESS</span>
<span class="title">[</span><span class="comment">INFO</span><span class="title">]</span> <span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span>
<span class="title">[</span><span class="comment">INFO</span><span class="title">]</span> <span class="comment">Total</span> <span class="comment">time:</span> <span class="comment">0</span><span class="string">.</span><span class="comment">294s</span>
<span class="title">[</span><span class="comment">INFO</span><span class="title">]</span> <span class="comment">Finished</span> <span class="comment">at:</span> <span class="comment">Fri</span> <span class="comment">Jan</span> <span class="comment">03</span> <span class="comment">10:24:04</span> <span class="comment">CST</span> <span class="comment">2014</span>
<span class="title">[</span><span class="comment">INFO</span><span class="title">]</span> <span class="comment">Final</span> <span class="comment">Memory:</span> <span class="comment">16M/963M</span>
<span class="title">[</span><span class="comment">INFO</span><span class="title">]</span> <span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span>
</pre></td></tr></table></figure>
</li>
<li><p>运行</p>
<figure class="highlight"><table><tr><td class="gutter"><pre>1
</pre></td><td class="code"><pre>[@sohu_41_173 target]$ java -<span class="keyword">cp</span> ./helloworld-<span class="number">1.0</span>-SNAPSHOT<span class="preprocessor">.jar</span> <span class="keyword">com</span><span class="preprocessor">.practise</span><span class="preprocessor">.java</span><span class="preprocessor">.App</span>
</pre></td></tr></table></figure>

</li>
</ul>
]]></content>
    <category scheme="http://lsmushroom.github.io/tags/java/" term="java"/>
    <category scheme="http://lsmushroom.github.io/categories/java/" term="java"/>
  </entry>
  <entry>
    <title type="html"><![CDATA[部署 Storm on Yarn]]></title>
    <link href="http://lsmushroom.github.io/2014/01/02/部署-storm-on-yarn/"/>
    <id>http://lsmushroom.github.io/2014/01/02/部署-storm-on-yarn/</id>
    <published>2014-01-02T07:44:50.000Z</published>
    <updated>2014-01-08T03:32:56.000Z</updated>
    <content type="html"><![CDATA[<p>本文基于apache hadoop2.2.0 版本部署storm-on-yarn ， 记录下将storm 部署在 Yarn 上运行的过程<br><a id="more"></a></p>
<h1 id="Precondition">Precondition</h1>
<ol>
<li>一个已部署好运行正常的yarn集群</li>
<li>一个已部署好运行正常的zookeeper集群</li>
</ol>
<h1 id="-90e8-7f72-">部署</h1>
<h2 id="-73af-5883-51c6-5907-">环境准备</h2>
<h3 id="1-_Java_7">1. Java 7</h3>
<p>Storm-on-yarn 要求其运行环境为<a href="">java 7</a> ，故需在集群内每个节点上将java版本升级为java 7</p>
<figure class="highlight"><table><tr><td class="gutter"><pre>1
2
3
4
5
</pre></td><td class="code"><pre>    <span class="title">[</span><span class="comment">root@master</span> <span class="comment">~</span><span class="title">]</span><span class="comment">#</span> <span class="comment">yum</span> <span class="literal">-</span><span class="comment">y</span> <span class="comment">install</span> <span class="comment">jdk</span><span class="literal">-</span><span class="comment">7u40</span><span class="literal">-</span><span class="comment">linux</span><span class="literal">-</span><span class="comment">x64</span><span class="string">.</span><span class="comment">rpm</span>
    <span class="title">[</span><span class="comment">root@master</span> <span class="comment">~</span><span class="title">]</span><span class="comment">#</span> <span class="comment">java</span> <span class="literal">-</span><span class="comment">version</span>
    <span class="comment">java</span> <span class="comment">version</span> <span class="comment">"1</span><span class="string">.</span><span class="comment">7</span><span class="string">.</span><span class="comment">0_40"</span>
    <span class="comment">Java(TM)</span> <span class="comment">SE</span> <span class="comment">Runtime</span> <span class="comment">Environment</span> <span class="comment">(build</span> <span class="comment">1</span><span class="string">.</span><span class="comment">7</span><span class="string">.</span><span class="comment">0_40</span><span class="literal">-</span><span class="comment">b43)</span>
    <span class="comment">Java</span> <span class="comment">HotSpot(TM)</span> <span class="comment">64</span><span class="literal">-</span><span class="comment">Bit</span> <span class="comment">Server</span> <span class="comment">VM</span> <span class="comment">(build</span> <span class="comment">24</span><span class="string">.</span><span class="comment">0</span><span class="literal">-</span><span class="comment">b56</span><span class="string">,</span> <span class="comment">mixed</span> <span class="comment">mode)</span>
</pre></td></tr></table></figure>

<p>相应的修改JAVA_HOME环境变量</p>
<h3 id="2-_-5b89-88c5-maven">2. 安装maven</h3>
<figure class="highlight"><table><tr><td class="gutter"><pre>1
2
3
4
</pre></td><td class="code"><pre>wget <span class="symbol">http:</span>/<span class="regexp">/mirror.symnds.com/software</span><span class="regexp">/Apache/maven</span><span class="regexp">/maven-3/</span><span class="number">3.1</span>.<span class="number">1</span>/binaries/apache-maven-<span class="number">3.1</span>.<span class="number">1</span>-bin.tar.gz
tar -zxvf apache-maven-<span class="number">3.1</span>.<span class="number">1</span>-bin.tar.gz
mv apache-maven-<span class="number">3.1</span>.<span class="number">1</span> /usr/lib/maven
export <span class="constant">PATH</span>=<span class="variable">$PATH</span><span class="symbol">:/usr/lib/maven/bin</span>
</pre></td></tr></table></figure>

<h2 id="-90e8-7f72-storm-yarn">部署storm-yarn</h2>
<h3 id="1-_-4e0b-8f7d-storm-on-yarn">1. 下载storm-on-yarn</h3>
<figure class="highlight"><table><tr><td class="gutter"><pre>1
2
3
</pre></td><td class="code"><pre><span class="comment">wget</span> <span class="comment">https://github</span><span class="string">.</span><span class="comment">com/yahoo/storm</span><span class="literal">-</span><span class="comment">yarn/archive/master</span><span class="string">.</span><span class="comment">zip</span>
<span class="comment">unzip</span> <span class="comment">master</span><span class="string">.</span><span class="comment">zip</span>
<span class="comment">cd</span> <span class="comment">storm</span><span class="literal">-</span><span class="comment">yarn</span><span class="literal">-</span><span class="comment">master</span>
</pre></td></tr></table></figure>

<h3 id="2-_-4fee-6539-pom-xml">2. 修改pom.xml</h3>
<p>当前是基于apache hadoop2.2.0 部署storm，需相应的修改pom.xml来指明</p>
<figure class="highlight"><table><tr><td class="gutter"><pre>1
2
3
4
5
6
</pre></td><td class="code"><pre>    <span class="tag">&lt;<span class="title">properties</span>&gt;</span>
    <span class="tag">&lt;<span class="title">storm.version</span>&gt;</span>0.9.0-wip21<span class="tag">&lt;/<span class="title">storm.version</span>&gt;</span>
    <span class="tag">&lt;<span class="title">hadoop.version</span>&gt;</span>2.2.0<span class="tag">&lt;/<span class="title">hadoop.version</span>&gt;</span>
    <span class="comment">&lt;!--hadoop.version&gt;2.1.0-beta&lt;/hadoop.version--&gt;</span>
    <span class="comment">&lt;!--hadoop.version&gt;2.1.0.2.0.5.0-67&lt;/hadoop.version--&gt;</span>
    <span class="tag">&lt;/<span class="title">properties</span>&gt;</span>
</pre></td></tr></table></figure>

<h3 id="3-_-90e8-7f72-storm">3. 部署storm</h3>
<p>在storm-yarn-master目录中包含storm.zip，创建$STORM_HOME目录用以存放storm.zip ，并将其解压</p>
<figure class="highlight"><table><tr><td class="gutter"><pre>1
2
</pre></td><td class="code"><pre><span class="keyword">cp</span> lib/storm<span class="preprocessor">.zip</span>  $STORM_HOME
unzip $STORM_HOME/storm<span class="preprocessor">.zip</span>
</pre></td></tr></table></figure>

<p>将storm-0.9.0-wip2 和 storm-yarn-master 的bin目录均添加至$PATH环境变量，以便后续使用storm和storm-yarn命令</p>
<p>将storm.zip文件上传至hdfs,注意此处hdfs上的路径需对应于当前的storm版本号，否则后续编译时的测试可能无法通过</p>
<figure class="highlight"><table><tr><td class="gutter"><pre>1
</pre></td><td class="code"><pre><span class="comment">hdfs</span> <span class="comment">dfs</span> <span class="literal">-</span><span class="comment">put</span> <span class="comment">storm</span><span class="string">.</span><span class="comment">zip</span>  <span class="comment">/lib/storm/0</span><span class="string">.</span><span class="comment">9</span><span class="string">.</span><span class="comment">0</span><span class="literal">-</span><span class="comment">wip2/</span>
</pre></td></tr></table></figure>

<h3 id="4-_-7f16-8bd1-storm-on-yarn">4. 编译storm-on-yarn</h3>
<figure class="highlight"><table><tr><td class="gutter"><pre>1
2
</pre></td><td class="code"><pre><span class="comment">cd</span> <span class="comment">storm</span><span class="literal">-</span><span class="comment">yarn</span><span class="literal">-</span><span class="comment">master</span>
<span class="comment">mvn</span> <span class="comment">package</span>
</pre></td></tr></table></figure>

<h3 id="5-_-7f16-8f91-storm-yaml-6587-4ef6-">5. 编辑storm.yaml文件</h3>
<p>storm通过storm.yaml来指定当前集群的拓扑信息</p>
<figure class="highlight"><table><tr><td class="gutter"><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
</pre></td><td class="code"><pre><span class="preprocessor">#指定storm使用的zookeeper集群</span>
<span class="label">storm.zookeeper.servers:</span>
- <span class="string">"10.1.41.173"</span>
- <span class="string">"10.1.41.181"</span>
- <span class="string">"10.1.41.183"</span>
- <span class="string">"10.1.41.184"</span>

<span class="preprocessor">#指定与zookeeper通信的端口，对应zookeeper配置中的client port</span>
<span class="label">storm.zookeeper.port:</span> <span class="number">2188</span>

<span class="preprocessor">#nimbus服务器地址</span>
<span class="label">nimbus.host:</span> <span class="string">"10.1.41.181"</span>

<span class="label">master.host:</span> <span class="string">"localhost"</span>
<span class="label">master.thrift.port:</span> <span class="number">9000</span>

<span class="preprocessor">#指定初始创建的supervisor数目</span>
master<span class="preprocessor">.initial</span>-num-supervisors: <span class="number">1</span>
<span class="label">master.container.priority:</span> <span class="number">0</span>

<span class="preprocessor">#指定storm-yarn启动的AM的Container占用的内存大小</span>
master<span class="preprocessor">.container</span><span class="preprocessor">.size</span>-mb: <span class="number">4096</span>

<span class="label">master.heartbeat.interval.millis:</span> <span class="number">1000</span>
<span class="label">master.timeout.secs:</span> <span class="number">1000</span>
<span class="label">yarn.report.wait.millis:</span> <span class="number">10000</span>
<span class="label">nimbusui.startup.ms:</span> <span class="number">10000</span>

<span class="label">ui.port:</span> <span class="number">7070</span>

<span class="label">storm.messaging.transport:</span> <span class="string">"backtype.storm.messaging.netty.Context"</span>
<span class="label">storm.messaging.netty.buffer_size:</span> <span class="number">1048576</span>
<span class="label">storm.messaging.netty.max_retries:</span> <span class="number">100</span>
<span class="label">storm.messaging.netty.min_wait_ms:</span> <span class="number">1000</span>
<span class="label">storm.messaging.netty.max_wait_ms:</span> <span class="number">5000</span>
</pre></td></tr></table></figure>

<h2 id="-8fd0-884c-storm-on-yarn">运行storm-on-yarn</h2>
<p>启动storm-yarn , 在此需注意，storm-yarn本身将作为Yarn上的一个应用被提交到yarn上，在多用户的环境中将同其他的MR job一样禁止使用root账号提交，否则在slave结点将因权限问题而启动失败，但不会输出error message至命令行终端上。</p>
<figure class="highlight"><table><tr><td class="gutter"><pre>1
</pre></td><td class="code"><pre><span class="comment">storm</span><span class="literal">-</span><span class="comment">yarn</span> <span class="comment">launch</span> <span class="comment">/opt/linsiyuan/hadoop</span><span class="literal">-</span><span class="comment">2</span><span class="string">.</span><span class="comment">2</span><span class="string">.</span><span class="comment">0/storm/storm</span><span class="literal">-</span><span class="comment">0</span><span class="string">.</span><span class="comment">9</span><span class="string">.</span><span class="comment">0</span><span class="literal">-</span><span class="comment">wip21/conf/storm</span><span class="string">.</span><span class="comment">yaml</span>
</pre></td></tr></table></figure>

<p>可通过web页面或以下命令来确认storm-on-yarn是否启动成功</p>
<figure class="highlight"><table><tr><td class="gutter"><pre>1
2
3
4
5
</pre></td><td class="code"><pre><span class="title">[</span><span class="comment">@master</span> <span class="comment">conf</span><span class="title">]</span><span class="comment">#</span> <span class="comment">yarn</span> <span class="comment">application</span> <span class="literal">-</span><span class="comment">list</span>
<span class="comment">14/01/02</span> <span class="comment">17:25:34</span> <span class="comment">INFO</span> <span class="comment">client</span><span class="string">.</span><span class="comment">RMProxy:</span> <span class="comment">Connecting</span> <span class="comment">to</span> <span class="comment">ResourceManager</span> <span class="comment">at</span> <span class="comment">master/10</span><span class="string">.</span><span class="comment">1</span><span class="string">.</span><span class="comment">41</span><span class="string">.</span><span class="comment">173:9080</span>
<span class="comment">Total</span> <span class="comment">number</span> <span class="comment">of</span> <span class="comment">applications</span> <span class="comment">(application</span><span class="literal">-</span><span class="comment">types:</span> <span class="title">[</span><span class="title">]</span> <span class="comment">and</span> <span class="comment">states:</span> <span class="title">[</span><span class="comment">SUBMITTED</span><span class="string">,</span> <span class="comment">ACCEPTED</span><span class="string">,</span> <span class="comment">RUNNING</span><span class="title">]</span><span class="comment">):1</span>
<span class="comment">Application</span><span class="literal">-</span><span class="comment">Id</span>      <span class="comment">Application</span><span class="literal">-</span><span class="comment">Name</span>        <span class="comment">Application</span><span class="literal">-</span><span class="comment">Type</span>          <span class="comment">User</span>           <span class="comment">Queue</span>                   <span class="comment">State</span>          <span class="comment">Final</span><span class="literal">-</span><span class="comment">State</span>              <span class="comment">Progress</span>                        <span class="comment">Tracking</span><span class="literal">-</span><span class="comment">URL</span>
<span class="comment">application_1388633522174_0003</span>         <span class="comment">Storm</span><span class="literal">-</span><span class="comment">on</span><span class="literal">-</span><span class="comment">Yarn</span>                    <span class="comment">YARN</span>     <span class="comment">yuanlinsi</span>         <span class="comment">default</span>                 <span class="comment">RUNNING</span>            <span class="comment">UNDEFINED</span>                   <span class="comment">50%</span>                                 <span class="comment">N/A</span>
</pre></td></tr></table></figure>

<p>注意storm-on-yarn的运行将占用大量的集群资源，尤其是虚拟内存，由此可能在storm-on-yarn启动后，因yarn中原有的对单个container可用内存资源上限的配置而将storm-on-yarn杀死。当前实验可暂时关闭对单个应用消耗虚拟内存的使用量, 在yarn-site.xml中添加以下配置项：</p>
<figure class="highlight"><table><tr><td class="gutter"><pre>1
2
3
4
5
6
</pre></td><td class="code"><pre><span class="tag">&lt;<span class="title">property</span>&gt;</span>
<span class="tag">&lt;<span class="title">description</span>&gt;</span>Whether virtual memory limits will be enforced for
containers.<span class="tag">&lt;/<span class="title">description</span>&gt;</span>
<span class="tag">&lt;<span class="title">name</span>&gt;</span>yarn.nodemanager.vmem-check-enabled<span class="tag">&lt;/<span class="title">name</span>&gt;</span>
<span class="tag">&lt;<span class="title">value</span>&gt;</span>false<span class="tag">&lt;/<span class="title">value</span>&gt;</span>
<span class="tag">&lt;/<span class="title">property</span>&gt;</span>
</pre></td></tr></table></figure>

<p>在nimbus等启动后将输出日志至类似如下的路径,可通过观察日志了解nimbus的运行状况</p>
<figure class="highlight"><table><tr><td class="gutter"><pre>1
2
3
4
5
6
7
</pre></td><td class="code"><pre><span class="comment">/opt/linsiyuan/hadoop</span><span class="literal">-</span><span class="comment">2</span><span class="string">.</span><span class="comment">2</span><span class="string">.</span><span class="comment">0/logs/root/userlogs/root/application_1388633522174_0002/container_1388633522174_0002_01_000001</span>
<span class="title">[</span><span class="comment">@slave0</span> <span class="comment">container_1388633522174_0002_01_000001</span><span class="title">]</span><span class="comment">#</span> <span class="comment">ll</span>
<span class="comment">total</span> <span class="comment">204</span>
<span class="literal">-</span><span class="comment">rw</span><span class="literal">-</span><span class="comment">r</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span> <span class="comment">1</span> <span class="comment">yuanlinsi</span> <span class="comment">hadoop</span> <span class="comment">179037</span> <span class="comment">Jan</span>  <span class="comment">2</span> <span class="comment">14:16</span> <span class="comment">nimbus</span><span class="string">.</span><span class="comment">log</span>
<span class="literal">-</span><span class="comment">rw</span><span class="literal">-</span><span class="comment">r</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span> <span class="comment">1</span> <span class="comment">yuanlinsi</span> <span class="comment">hadoop</span>    <span class="comment">531</span> <span class="comment">Jan</span>  <span class="comment">2</span> <span class="comment">11:34</span> <span class="comment">stderr</span>
<span class="literal">-</span><span class="comment">rw</span><span class="literal">-</span><span class="comment">r</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span> <span class="comment">1</span> <span class="comment">yuanlinsi</span> <span class="comment">hadoop</span>  <span class="comment">17644</span> <span class="comment">Jan</span>  <span class="comment">2</span> <span class="comment">14:15</span> <span class="comment">stdout</span>
<span class="literal">-</span><span class="comment">rw</span><span class="literal">-</span><span class="comment">r</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span> <span class="comment">1</span> <span class="comment">yuanlinsi</span> <span class="comment">hadoop</span>   <span class="comment">1670</span> <span class="comment">Jan</span>  <span class="comment">2</span> <span class="comment">11:56</span> <span class="comment">ui</span><span class="string">.</span><span class="comment">log</span>
</pre></td></tr></table></figure>

<p>获取storm.yaml</p>
<figure class="highlight"><table><tr><td class="gutter"><pre>1
</pre></td><td class="code"><pre><span class="comment">storm</span><span class="literal">-</span><span class="comment">yarn</span> <span class="comment">getStormConfig</span> <span class="literal">-</span><span class="comment">appId</span> <span class="comment">application_1388633522174_0002</span> <span class="literal">-</span><span class="comment">output</span> <span class="comment">~/</span><span class="string">.</span><span class="comment">storm/storm</span><span class="string">.</span><span class="comment">yaml</span>
</pre></td></tr></table></figure>

<p>由获得的storm.yaml可知当前nimbus在哪个结点并提交任务：</p>
<figure class="highlight"><table><tr><td class="gutter"><pre>1
</pre></td><td class="code"><pre><span class="comment">storm</span> <span class="comment">jar</span> <span class="comment">/opt/linsiyuan/hadoop</span><span class="literal">-</span><span class="comment">2</span><span class="string">.</span><span class="comment">2</span><span class="string">.</span><span class="comment">0/storm/storm</span><span class="literal">-</span><span class="comment">yarn</span><span class="literal">-</span><span class="comment">master/lib/storm</span><span class="literal">-</span><span class="comment">starter</span><span class="literal">-</span><span class="comment">0</span><span class="string">.</span><span class="comment">0</span><span class="string">.</span><span class="comment">1</span><span class="literal">-</span><span class="comment">SNAPSHOT</span><span class="string">.</span><span class="comment">jar</span> <span class="comment">storm</span><span class="string">.</span><span class="comment">starter</span><span class="string">.</span><span class="comment">WordCountTopology</span> <span class="comment">WordCountTopology</span> <span class="literal">-</span><span class="comment">c</span> <span class="comment">nimbus</span><span class="string">.</span><span class="comment">host=10</span><span class="string">.</span><span class="comment">1</span><span class="string">.</span><span class="comment">41</span><span class="string">.</span><span class="comment">183</span>
</pre></td></tr></table></figure>

<p>可通过通过$nimbus.host:7070访问storm 的web UI 来监测topology的执行</p>
<p>Done. :)</p>
]]></content>
    <category scheme="http://lsmushroom.github.io/tags/yarn/" term="yarn"/>
    <category scheme="http://lsmushroom.github.io/categories/yarn/" term="yarn"/>
  </entry>
  <entry>
    <title type="html"><![CDATA[Storm on Yarn 部署]]></title>
    <link href="http://lsmushroom.github.io/2013/12/25/storm-on-yarn-部署/"/>
    <id>http://lsmushroom.github.io/2013/12/25/storm-on-yarn-部署/</id>
    <published>2013-12-25T12:55:03.000Z</published>
    <updated>2014-03-16T04:07:38.000Z</updated>
    <content type="html"><![CDATA[<a id="more"></a>

<h2 id="-51c6-5907-5b89-88c5-73af-5883-">准备安装环境</h2>
<ol>
<li><p>下载<a href="https://github.com/yahoo/storm-yarn/archive/master.zip" target="_blank">storm-on-yarn</a><br> wget <a href="https://github.com/yahoo/storm-yarn/archive/master.zip" target="_blank">https://github.com/yahoo/storm-yarn/archive/master.zip</a><br> 或<br> git clone git@github.com:yahoo/storm-yarn.git</p>
</li>
<li><p>创建一个目录用以存放storm相关文件<br> mkdir storm</p>
</li>
<li>将storm.zip文件拷贝至$STORM_HOME目录并解压<br> cp ./storm-yarn-master/lib/storm.zip .<br> unzip storm.zip</li>
</ol>
<h2 id="Storm_-4f9d-8d56-7684-8f6f-4ef6-73af-5883-">Storm 依赖的软件环境</h2>
<ol>
<li><a href="http://zeromq.org/area:download" target="_blank">zeromq</a></li>
<li><a href="https://github.com/nathanmarz/jzmq" target="_blank">jzmq</a></li>
<li>Java 6</li>
<li>Python</li>
</ol>
<h2 id="-6dfb-52a0-73af-5883-53d8-91cf-">添加环境变量</h2>
<p>将storm-0.9.0-wip21 和 storm-yarn-master/bin 目录至 $PATH 环境变量中</p>
<figure class="highlight"><table><tr><td class="gutter"><pre>1
</pre></td><td class="code"><pre><span class="comment">export</span> <span class="comment">PATH=/opt/linsiyuan/hadoop</span><span class="literal">-</span><span class="comment">2</span><span class="string">.</span><span class="comment">2</span><span class="string">.</span><span class="comment">0/storm/storm</span><span class="literal">-</span><span class="comment">0</span><span class="string">.</span><span class="comment">9</span><span class="string">.</span><span class="comment">0</span><span class="literal">-</span><span class="comment">wip21:/opt/linsiyuan/hadoop</span><span class="literal">-</span><span class="comment">2</span><span class="string">.</span><span class="comment">2</span><span class="string">.</span><span class="comment">0/storm/storm</span><span class="literal">-</span><span class="comment">yarn</span><span class="literal">-</span><span class="comment">master/bin:$PATH</span>
</pre></td></tr></table></figure>

<h2 id="-7f16-8bd1-">编译</h2>
<p>进入storm-yarn-master目录，编译<br>    mvn package -DskipTests</p>
<h2 id="-90e8-7f72-zookeeper">部署zookeeper</h2>
<p>zookeeper需要投票选举，因此建议在搭建zookeeper集群时包含奇数个结点,当包含偶数个结点时，将无法处理偶数个结点同时挂掉的情况。</p>
<ol>
<li>准备Java 1.6运行环境</li>
<li>Set the Java heap size. This is very important to avoid swapping, which will seriously degrade ZooKeeper performance. To determine the correct value, use load tests, and make sure you are well below the usage limit that would cause you to swap. Be conservative - use a maximum heap size of 3GB for a 4GB machine.</li>
<li>下载<a href="http://zookeeper.apache.org/releases.html#download" target="_blank">zookeeper安装包</a></li>
<li>创建配置文件，包含以下内容,配置文件名随意,通常命名为$ZOOKEEPER_HOME/conf/zoo.cfg<figure class="highlight"><table><tr><td class="gutter"><pre>1
2
3
4
5
6
7
8
</pre></td><td class="code"><pre><span class="title">tickTime</span>=<span class="number">2000</span>
<span class="title">dataDir</span>=/var/zookeeper/
<span class="title">clientPort</span>=<span class="number">2181</span>
<span class="title">initLimit</span>=<span class="number">5</span>
<span class="title">syncLimit</span>=<span class="number">2</span>
<span class="title">server</span><span class="number">.1</span>=zoo1:<span class="number">2888</span>:<span class="number">3888</span>
<span class="title">server</span><span class="number">.2</span>=zoo2:<span class="number">2888</span>:<span class="number">3888</span>
<span class="title">server</span><span class="number">.3</span>=zoo3:<span class="number">2888</span>:<span class="number">3888</span>
</pre></td></tr></table></figure>

</li>
</ol>
<p>以上配置文件主要用于zookeeper集群中各个结点了解集群内的其他结点的信息。这主要是通过配置项server.id=host:port:port</p>
<ol>
<li>将zookeeper同步至集群内的其他结点</li>
<li>在相应的结点上在$dataDir中指定的目录中创建相应的id文件，其中内容仅包含结点所对应的id信息 </li>
</ol>
]]></content>
    <category scheme="http://lsmushroom.github.io/tags/yarn/" term="yarn"/>
    <category scheme="http://lsmushroom.github.io/tags/storm/" term="storm"/>
    <category scheme="http://lsmushroom.github.io/categories/yarn/" term="yarn"/>
  </entry>
  <entry>
    <title type="html"><![CDATA[Yarn 多用户权限配置]]></title>
    <link href="http://lsmushroom.github.io/2013/12/23/yarn-多用户权限配置/"/>
    <id>http://lsmushroom.github.io/2013/12/23/yarn-多用户权限配置/</id>
    <published>2013-12-23T07:32:23.000Z</published>
    <updated>2014-02-25T12:42:14.000Z</updated>
    <content type="html"><![CDATA[<p>近期将在yarn集群中添加多用户环境，修改了下集群的用户访问权限，记录下已备忘。</p>
<p><a id="more"></a></p>
<h1 id="-6e90-7801-5206-6790-">源码分析</h1>
<p>首先需清楚在yarn集群中将存在两类用户，一个是启动集群的用户，另一个是提交应用的用户。由此对于Yarn中的守护进程，如ResourceManager，NodeManager,NameNode,DataNode等将由管理员用户启动，而如MRAppMaster,YarnChild类，在多用户情景下应由提交应用的用户所启动。由此多用户将与Yarn中容器启动的过程紧密相关，在Yarn中提供两种实现方式：DefaultContainerExecutor和LinuxContainerExecutor，二者的执行逻辑很相似，主要的不同之处在于DefaultContainerExecutor将以NodeManager启动者的用户运行相应的应用，而LinuxContainerExecutor可以提交应用的用户执行，同时LinuxContainerExecutor可实现对CPU资源的控制。而LinuxContainerExecutor的执行则依赖二进制可执行程序container-executor来完成。</p>
<p>对应用程序的启动必然涉及到一个用户的切换过程，而这个操作就是由Yarn中的container-executor来完成的。<br>container-executor 所支持的命令行参数如下：</p>
<figure class="highlight"><table><tr><td class="gutter"><pre>1
2
3
4
5
6
7
8
9
</pre></td><td class="code"><pre><span class="title">[</span><span class="comment">@slave0</span> <span class="comment">bin</span><span class="title">]</span><span class="comment">#</span> <span class="string">.</span><span class="comment">/container</span><span class="literal">-</span><span class="comment">executor</span>
<span class="comment">Usage:</span> <span class="comment">container</span><span class="literal">-</span><span class="comment">executor</span> <span class="literal">-</span><span class="literal">-</span><span class="comment">checksetup</span>
<span class="comment">Usage:</span> <span class="comment">container</span><span class="literal">-</span><span class="comment">executor</span> <span class="literal">-</span><span class="literal">-</span><span class="comment">mount</span><span class="literal">-</span><span class="comment">cgroups</span> <span class="comment">hierarchy</span> <span class="comment">controller=path</span><span class="string">.</span><span class="string">.</span><span class="string">.</span>
<span class="comment">Usage:</span> <span class="comment">container</span><span class="literal">-</span><span class="comment">executor</span> <span class="comment">user</span> <span class="comment">command</span> <span class="comment">command</span><span class="literal">-</span><span class="comment">args</span>
<span class="comment">Commands:</span>
<span class="comment">initialize</span> <span class="comment">container:</span>  <span class="comment">0</span> <span class="comment">appid</span> <span class="comment">tokens</span> <span class="comment">nm</span><span class="literal">-</span><span class="comment">local</span><span class="literal">-</span><span class="comment">dirs</span> <span class="comment">nm</span><span class="literal">-</span><span class="comment">log</span><span class="literal">-</span><span class="comment">dirs</span> <span class="comment">cmd</span> <span class="comment">app</span><span class="string">.</span><span class="string">.</span><span class="string">.</span>
<span class="comment">launch</span> <span class="comment">container:</span>     <span class="comment">1</span> <span class="comment">appid</span> <span class="comment">containerid</span> <span class="comment">workdir</span> <span class="comment">container</span><span class="literal">-</span><span class="comment">script</span> <span class="comment">tokens</span> <span class="comment">pidfile</span> <span class="comment">nm</span><span class="literal">-</span><span class="comment">local</span><span class="literal">-</span><span class="comment">dirs</span> <span class="comment">nm</span><span class="literal">-</span><span class="comment">log</span><span class="literal">-</span><span class="comment">dirs</span> <span class="comment">resources</span>
<span class="comment">signal</span> <span class="comment">container:</span>     <span class="comment">2</span> <span class="comment">container</span><span class="literal">-</span><span class="comment">pid</span> <span class="comment">signal</span>
<span class="comment">delete</span> <span class="comment">as</span> <span class="comment">user:</span>  <span class="comment">3</span> <span class="comment">relative</span><span class="literal">-</span><span class="comment">path</span>
</pre></td></tr></table></figure>

<p>通过跟踪Container启动日志可以了解其启动过程：</p>
<figure class="highlight"><table><tr><td class="gutter"><pre>1
2
3
</pre></td><td class="code"><pre><span class="comment">2013</span><span class="literal">-</span><span class="comment">12</span><span class="literal">-</span><span class="comment">23</span> <span class="comment">19:02:21</span><span class="string">,</span><span class="comment">171</span> <span class="comment">INFO</span> <span class="comment">nodemanager</span><span class="string">.</span><span class="comment">LinuxContainerExecutor:</span> <span class="comment">initApplication:</span> <span class="title">[</span><span class="comment">/opt/linsiyuan/hadoop</span><span class="literal">-</span><span class="comment">2</span><span class="string">.</span><span class="comment">2</span><span class="string">.</span><span class="comment">0/bin/container</span><span class="literal">-</span><span class="comment">executor</span><span class="string">,</span> <span class="comment">smartidc</span><span class="string">,</span> <span class="comment">0</span><span class="string">,</span> <span class="comment">application_1387731734171_0098</span><span class="string">,</span> <span class="comment">/tmp/hadoop</span><span class="literal">-</span><span class="comment">root/nm</span><span class="literal">-</span><span class="comment">local</span><span class="literal">-</span><span class="comment">dir/nmPrivate/container_1387731734171_0098_01_000003</span><span class="string">.</span><span class="comment">tokens</span><span class="string">,</span> <span class="comment">/tmp/hadoop</span><span class="literal">-</span><span class="comment">root/nm</span><span class="literal">-</span><span class="comment">local</span><span class="literal">-</span><span class="comment">dir</span><span class="string">,</span> <span class="comment">/opt/linsiyuan/hadoop</span><span class="literal">-</span><span class="comment">2</span><span class="string">.</span><span class="comment">2</span><span class="string">.</span><span class="comment">0/logs/root/userlogs/root</span><span class="string">,</span> <span class="comment">/usr/lib/jvm/java</span><span class="literal">-</span><span class="comment">1</span><span class="string">.</span><span class="comment">6</span><span class="string">.</span><span class="comment">0</span><span class="literal">-</span><span class="comment">sun</span><span class="literal">-</span><span class="comment">1</span><span class="string">.</span><span class="comment">6</span><span class="string">.</span><span class="comment">0</span><span class="string">.</span><span class="comment">45</span><span class="string">.</span><span class="comment">x86_64/jre/bin/java</span><span class="string">,</span> <span class="literal">-</span><span class="comment">classpath</span><span class="string">,</span> <span class="string">.</span><span class="string">.</span><span class="string">.</span> <span class="string">,</span> <span class="literal">-</span><span class="comment">Djava</span><span class="string">.</span><span class="comment">library</span><span class="string">.</span><span class="comment">path=/opt/linsiyuan/hadoop</span><span class="literal">-</span><span class="comment">2</span><span class="string">.</span><span class="comment">2</span><span class="string">.</span><span class="comment">0/lib/native</span><span class="string">,</span> <span class="comment">org</span><span class="string">.</span><span class="comment">apache</span><span class="string">.</span><span class="comment">hadoop</span><span class="string">.</span><span class="comment">yarn</span><span class="string">.</span><span class="comment">server</span><span class="string">.</span><span class="comment">nodemanager</span><span class="string">.</span><span class="comment">containermanager</span><span class="string">.</span><span class="comment">localizer</span><span class="string">.</span><span class="comment">ContainerLocalizer</span><span class="string">,</span> <span class="comment">smartidc</span><span class="string">,</span> <span class="comment">application_1387731734171_0098</span><span class="string">,</span> <span class="comment">container_1387731734171_0098_01_000003</span><span class="string">,</span> <span class="comment">slave0</span><span class="string">,</span> <span class="comment">8040</span><span class="string">,</span> <span class="comment">/tmp/hadoop</span><span class="literal">-</span><span class="comment">root/nm</span><span class="literal">-</span><span class="comment">local</span><span class="literal">-</span><span class="comment">dir</span><span class="title">]</span>

<span class="comment">2013</span><span class="literal">-</span><span class="comment">12</span><span class="literal">-</span><span class="comment">23</span> <span class="comment">19:02:22</span><span class="string">,</span><span class="comment">907</span> <span class="comment">INFO</span> <span class="comment">nodemanager</span><span class="string">.</span><span class="comment">LinuxContainerExecutor:</span> <span class="comment">launchContainer:</span> <span class="title">[</span><span class="comment">/opt/linsiyuan/hadoop</span><span class="literal">-</span><span class="comment">2</span><span class="string">.</span><span class="comment">2</span><span class="string">.</span><span class="comment">0/bin/container</span><span class="literal">-</span><span class="comment">executor</span><span class="string">,</span> <span class="comment">smartidc</span><span class="string">,</span> <span class="comment">1</span><span class="string">,</span> <span class="comment">application_1387731734171_0098</span><span class="string">,</span> <span class="comment">container_1387731734171_0098_01_000003</span><span class="string">,</span> <span class="comment">/tmp/hadoop</span><span class="literal">-</span><span class="comment">root/nm</span><span class="literal">-</span><span class="comment">local</span><span class="literal">-</span><span class="comment">dir/usercache/smartidc/appcache/application_1387731734171_0098/container_1387731734171_0098_01_000003</span><span class="string">,</span> <span class="comment">/tmp/hadoop</span><span class="literal">-</span><span class="comment">root/nm</span><span class="literal">-</span><span class="comment">local</span><span class="literal">-</span><span class="comment">dir/nmPrivate/application_1387731734171_0098/container_1387731734171_0098_01_000003/launch_container</span><span class="string">.</span><span class="comment">sh</span><span class="string">,</span> <span class="comment">/tmp/hadoop</span><span class="literal">-</span><span class="comment">root/nm</span><span class="literal">-</span><span class="comment">local</span><span class="literal">-</span><span class="comment">dir/nmPrivate/application_1387731734171_0098/container_1387731734171_0098_01_000003/container_1387731734171_0098_01_000003</span><span class="string">.</span><span class="comment">tokens</span><span class="string">,</span> <span class="comment">/tmp/hadoop</span><span class="literal">-</span><span class="comment">root/nm</span><span class="literal">-</span><span class="comment">local</span><span class="literal">-</span><span class="comment">dir/nmPrivate/container_1387731734171_0098_01_000003</span><span class="string">.</span><span class="comment">pid</span><span class="string">,</span> <span class="comment">/tmp/hadoop</span><span class="literal">-</span><span class="comment">root/nm</span><span class="literal">-</span><span class="comment">local</span><span class="literal">-</span><span class="comment">dir</span><span class="string">,</span> <span class="comment">/opt/linsiyuan/hadoop</span><span class="literal">-</span><span class="comment">2</span><span class="string">.</span><span class="comment">2</span><span class="string">.</span><span class="comment">0/logs/root/userlogs/root</span><span class="string">,</span> <span class="comment">cgroups=/cgroup/cpu/yarn/container_1387731734171_0098_01_000003/tasks</span><span class="title">]</span>
</pre></td></tr></table></figure>

<p>以上两条日志记录了容器的初始化及启动命令。注意观察在可执行程序后紧跟的第一个参数即为提交应用的用户名。</p>
<p>container-executor将基于此参数设置用户的有效用户ID及组ID，但首先需结合配置文件container-executor.cfg对参数做检查，检查的标准如下：</p>
<figure class="highlight"><table><tr><td class="gutter"><pre>1
2
3
4
5
6
7
8
9
</pre></td><td class="code"><pre><span class="javadoc">/**
 * Is the user a real user account?
 * Checks:
 *   1. Not root
 *   2. UID is above the minimum configured.
 *   3. Not in banned user list
 * Returns NULL on failure
 */</span>
struct passwd* check_user(<span class="keyword">const</span> <span class="keyword">char</span> *user)
</pre></td></tr></table></figure>

<p>也即在使用LinuxContainerExecutor时，禁止root用户提交job，对提交job的用户uid小于container-executor.cfg中设置的最小用户id及处于黑名单中的用户同样禁止提交job</p>
<p>当提交job的用户通过检查后，最终将通过系统调用 seteuid及setegid 完成有效用户（组）ID的切换</p>
<h1 id="-914d-7f6e-">配置</h1>
<h2 id="-5207-6362-Yarn-4f7f-7528-7684-ContainerExecutor-7c7b-4e3a-LinuxContainerExecutor">切换Yarn使用的ContainerExecutor类为LinuxContainerExecutor</h2>
<p>在yarn-site.xml文件中添加以下内容并同步至集群中其他节点</p>
<figure class="highlight"><table><tr><td class="gutter"><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
</pre></td><td class="code"><pre>&lt;!--Start set the <span class="keyword">container</span>-executor to LinuxContainerExecutor--&gt;
&lt;property&gt;
&lt;description&gt;who will execute(launch) the containers.&lt;/description&gt;
&lt;name&gt;yarn.nodemanager.<span class="keyword">container</span>-executor.<span class="class"><span class="keyword">class</span>&lt;/<span class="title">name</span>&gt;
&lt;<span class="title">value</span>&gt;<span class="title">org</span>.<span class="title">apache</span>.<span class="title">hadoop</span>.<span class="title">yarn</span>.<span class="title">server</span>.<span class="title">nodemanager</span>.<span class="title">LinuxContainerExecutor</span>&lt;/<span class="title">value</span>&gt;
&lt;/<span class="title">property</span>&gt;

&lt;<span class="title">property</span>&gt;
&lt;<span class="title">description</span>&gt;<span class="title">The</span> <span class="title">class</span> <span class="title">which</span> <span class="title">should</span> <span class="title">help</span> <span class="title">the</span> <span class="title">LCE</span> <span class="title">handle</span> <span class="title">resources</span>.&lt;/<span class="title">description</span>&gt;
&lt;<span class="title">name</span>&gt;<span class="title">yarn</span>.<span class="title">nodemanager</span>.<span class="title">linux</span>-<span class="title">container</span>-<span class="title">executor</span>.<span class="title">resources</span>-<span class="title">handler</span>.<span class="title">class</span>&lt;/<span class="title">name</span>&gt;
&lt;<span class="title">value</span>&gt;<span class="title">org</span>.<span class="title">apache</span>.<span class="title">hadoop</span>.<span class="title">yarn</span>.<span class="title">server</span>.<span class="title">nodemanager</span>.<span class="title">util</span>.<span class="title">CgroupsLCEResourcesHandler</span>&lt;/<span class="title">value</span>&gt;
&lt;/<span class="title">property</span>&gt;

&lt;<span class="title">property</span>&gt;
&lt;<span class="title">description</span>&gt;<span class="title">The</span> <span class="title">cgroups</span> <span class="title">hierarchy</span> <span class="title">under</span> <span class="title">which</span> <span class="title">to</span> <span class="title">place</span> <span class="title">YARN</span> <span class="title">proccesses</span> (<span class="title">cannot</span> <span class="title">contain</span> <span class="title">commas</span>).
<span class="title">If</span> <span class="title">yarn</span>.<span class="title">nodemanager</span>.<span class="title">linux</span>-<span class="title">container</span>-<span class="title">executor</span>.<span class="title">cgroups</span>.<span class="title">mount</span> <span class="title">is</span> <span class="title">false</span> (<span class="title">that</span> <span class="title">is</span>, <span class="title">if</span> <span class="title">cgroups</span> <span class="title">have</span>
        <span class="title">been</span> <span class="title">pre</span>-<span class="title">configured</span>), <span class="title">then</span> <span class="title">this</span> <span class="title">cgroups</span> <span class="title">hierarchy</span> <span class="title">must</span> <span class="title">already</span> <span class="title">exist</span> <span class="title">and</span> <span class="title">be</span> <span class="title">writable</span> <span class="title">by</span> <span class="title">the</span>
<span class="title">NodeManager</span> <span class="title">user</span>, <span class="title">otherwise</span> <span class="title">the</span> <span class="title">NodeManager</span> <span class="title">may</span> <span class="title">fail</span>.
<span class="title">Only</span> <span class="title">used</span> <span class="title">when</span> <span class="title">the</span> <span class="title">LCE</span> <span class="title">resources</span> <span class="title">handler</span> <span class="title">is</span> <span class="title">set</span> <span class="title">to</span> <span class="title">the</span> <span class="title">CgroupsLCEResourcesHandler</span>.&lt;/<span class="title">description</span>&gt;
&lt;<span class="title">name</span>&gt;<span class="title">yarn</span>.<span class="title">nodemanager</span>.<span class="title">linux</span>-<span class="title">container</span>-<span class="title">executor</span>.<span class="title">cgroups</span>.<span class="title">hierarchy</span>&lt;/<span class="title">name</span>&gt;
&lt;<span class="title">value</span>&gt;/<span class="title">yarn</span>&lt;/<span class="title">value</span>&gt;
&lt;/<span class="title">property</span>&gt;

&lt;<span class="title">property</span>&gt;
&lt;<span class="title">description</span>&gt;<span class="title">Whether</span> <span class="title">the</span> <span class="title">LCE</span> <span class="title">should</span> <span class="title">attempt</span> <span class="title">to</span> <span class="title">mount</span> <span class="title">cgroups</span> <span class="title">if</span> <span class="title">not</span> <span class="title">found</span>.
<span class="title">Only</span> <span class="title">used</span> <span class="title">when</span> <span class="title">the</span> <span class="title">LCE</span> <span class="title">resources</span> <span class="title">handler</span> <span class="title">is</span> <span class="title">set</span> <span class="title">to</span> <span class="title">the</span> <span class="title">CgroupsLCEResourcesHandler</span>.&lt;/<span class="title">description</span>&gt;
&lt;<span class="title">name</span>&gt;<span class="title">yarn</span>.<span class="title">nodemanager</span>.<span class="title">linux</span>-<span class="title">container</span>-<span class="title">executor</span>.<span class="title">cgroups</span>.<span class="title">mount</span>&lt;/<span class="title">name</span>&gt;
&lt;<span class="title">value</span>&gt;<span class="title">true</span>&lt;/<span class="title">value</span>&gt;
&lt;/<span class="title">property</span>&gt;

&lt;<span class="title">property</span>&gt;
&lt;<span class="title">description</span>&gt;<span class="title">Where</span> <span class="title">the</span> <span class="title">LCE</span> <span class="title">should</span> <span class="title">attempt</span> <span class="title">to</span> <span class="title">mount</span> <span class="title">cgroups</span> <span class="title">if</span> <span class="title">not</span> <span class="title">found</span>. <span class="title">Common</span> <span class="title">locations</span>
<span class="title">include</span> /<span class="title">sys</span>/<span class="title">fs</span>/<span class="title">cgroup</span> <span class="title">and</span> /<span class="title">cgroup</span>; <span class="title">the</span> <span class="title">default</span> <span class="title">location</span> <span class="title">can</span> <span class="title">vary</span> <span class="title">depending</span> <span class="title">on</span> <span class="title">the</span> <span class="title">Linux</span>  <span class="title">distribution</span> <span class="title">in</span> <span class="title">use</span>. <span class="title">This</span> <span class="title">path</span> <span class="title">must</span> <span class="title">exist</span> <span class="title">before</span> <span class="title">the</span> <span class="title">NodeManager</span> <span class="title">is</span> <span class="title">launched</span>.
<span class="title">Only</span> <span class="title">used</span> <span class="title">when</span> <span class="title">the</span> <span class="title">LCE</span> <span class="title">resources</span> <span class="title">handler</span> <span class="title">is</span> <span class="title">set</span> <span class="title">to</span> <span class="title">the</span> <span class="title">CgroupsLCEResourcesHandler</span>, <span class="title">and</span>
<span class="title">yarn</span>.<span class="title">nodemanager</span>.<span class="title">linux</span>-<span class="title">container</span>-<span class="title">executor</span>.<span class="title">cgroups</span>.<span class="title">mount</span> <span class="title">is</span> <span class="title">true</span>.&lt;/<span class="title">description</span>&gt;
&lt;<span class="title">name</span>&gt;<span class="title">yarn</span>.<span class="title">nodemanager</span>.<span class="title">linux</span>-<span class="title">container</span>-<span class="title">executor</span>.<span class="title">cgroups</span>.<span class="title">mount</span>-<span class="title">path</span>&lt;/<span class="title">name</span>&gt;
&lt;<span class="title">value</span>&gt;/<span class="title">cgroup</span>&lt;/<span class="title">value</span>&gt;
&lt;/<span class="title">property</span>&gt;

&lt;<span class="title">property</span>&gt;
&lt;<span class="title">name</span>&gt;<span class="title">yarn</span>.<span class="title">nodemanager</span>.<span class="title">linux</span>-<span class="title">container</span>-<span class="title">executor</span>.<span class="title">group</span>&lt;/<span class="title">name</span>&gt;
&lt;<span class="title">value</span>&gt;<span class="title">yarn</span>&lt;/<span class="title">value</span>&gt;
&lt;<span class="title">description</span>&gt;<span class="title">your</span> <span class="title">user</span> <span class="title">group</span> <span class="title">here</span>. <span class="title">should</span> <span class="title">match</span> <span class="title">container</span>-<span class="title">executor</span>.<span class="title">cfg</span>&lt;/<span class="title">description</span>&gt;
&lt;/<span class="title">property</span>&gt;</span>
</pre></td></tr></table></figure>

<h2 id="container-executor-cfg_-914d-7f6e-">container-executor.cfg 配置</h2>
<p>配置项yarn.nodemanager.linux-container-executor.group 对应yarn-site.xml中yarn.nodemanager.linux-container-executor.group,二者需保持一致<br>配置项banned.users 为黑名单<br>配置项min.user.id 指定可向集群提交job的最小用户UID，通常新增的用户的UID从500开始<br>配置项allowed.system.users 为白名单</p>
<figure class="highlight"><table><tr><td class="gutter"><pre>1
2
3
4
5
6
7
8
9
10
</pre></td><td class="code"><pre>[@slave0 hadoop-<span class="number">2.2</span><span class="number">.0</span>]<span class="preprocessor"># cat etc/hadoop/container-executor.cfg</span>
yarn<span class="preprocessor">.nodemanager</span><span class="preprocessor">.linux</span>-container-executor<span class="preprocessor">.group</span>=hadoop
banned<span class="preprocessor">.users</span>=<span class="preprocessor">#comma separated list of users who can not run applications</span>
min<span class="preprocessor">.user</span><span class="preprocessor">.id</span>=<span class="number">499</span>
allowed<span class="preprocessor">.system</span><span class="preprocessor">.users</span>=

<span class="preprocessor">#yarn.nodemanager.linux-container-executor.group=#configured value of yarn.nodemanager.linux-container-executor.group</span>
<span class="preprocessor">#banned.users=#comma separated list of users who can not run applications</span>
<span class="preprocessor">#min.user.id=1000#Prevent other super-users</span>
<span class="preprocessor">#allowed.system.users=##comma separated list of system users who CAN run applications</span>
</pre></td></tr></table></figure>

<h2 id="-6743-9650-8bbe-7f6e-">权限设置</h2>
<h3 id="container-executor-6743-9650-8bbe-7f6e-">container-executor权限设置</h3>
<p>container-executor可执行文件对权限及所属的用户和用户组有严格的要求,需按如下方式设置：</p>
<figure class="highlight"><table><tr><td class="gutter"><pre>1
2
3
4
</pre></td><td class="code"><pre><span class="title">[</span><span class="comment">@slave0</span> <span class="comment">hadoop</span><span class="literal">-</span><span class="comment">2</span><span class="string">.</span><span class="comment">2</span><span class="string">.</span><span class="comment">0</span><span class="title">]</span><span class="comment">#</span> <span class="comment">chown</span> <span class="comment">root:hadoop</span> <span class="string">.</span><span class="comment">/container</span><span class="literal">-</span><span class="comment">executor</span>
<span class="title">[</span><span class="comment">@slave0</span> <span class="comment">hadoop</span><span class="literal">-</span><span class="comment">2</span><span class="string">.</span><span class="comment">2</span><span class="string">.</span><span class="comment">0</span><span class="title">]</span><span class="comment">#</span> <span class="comment">chmod</span> <span class="comment">6050</span> <span class="string">.</span><span class="comment">/container</span><span class="literal">-</span><span class="comment">executor</span>
<span class="title">[</span><span class="comment">@slave0</span> <span class="comment">hadoop</span><span class="literal">-</span><span class="comment">2</span><span class="string">.</span><span class="comment">2</span><span class="string">.</span><span class="comment">0</span><span class="title">]</span><span class="comment">#</span> <span class="comment">ll</span> <span class="comment">bin/container</span><span class="literal">-</span><span class="comment">executor</span>
<span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="comment">Sr</span><span class="literal">-</span><span class="comment">s</span><span class="literal">-</span><span class="literal">-</span><span class="literal">-</span> <span class="comment">1</span> <span class="comment">root</span> <span class="comment">hadoop</span> <span class="comment">101927</span> <span class="comment">Nov</span> <span class="comment">14</span> <span class="comment">17:46</span> <span class="comment">bin/container</span><span class="literal">-</span><span class="comment">executor</span>
</pre></td></tr></table></figure>

<h3 id="-24-HADOOP_HOME-2f-etc-2c-24-HADOOP_HOME-6743-9650-8bbe-7f6e-">$HADOOP_HOME/etc,$HADOOP_HOME权限设置</h3>
<p>要求etc/hadoop/container-executor.cfg , $HADOOP_HOME/etc,$HADOOP_HOME目录的所有者必须为集群的启动者</p>
<h2 id="cgroup_-9ed8-8ba4-6302-8f7d-70b9-">cgroup 默认挂载点</h2>
<p>yarn-site.xml中yarn.nodemanager.linux-container-executor.cgroups.mount-path 指定的默认挂载点要求必须存在，可在集群内每个节点上运行/etc/init.d/cgconfig restart以确保挂载点的存在</p>
<h2 id="-7528-6237-6dfb-52a0-">用户添加</h2>
<p>在集群内的每个节点上都需要新增相应的集群使用者用户账号</p>
]]></content>
    <category scheme="http://lsmushroom.github.io/tags/yarn/" term="yarn"/>
    <category scheme="http://lsmushroom.github.io/tags/hadoop/" term="hadoop"/>
    <category scheme="http://lsmushroom.github.io/categories/yarn/" term="yarn"/>
  </entry>
  <entry>
    <title type="html"><![CDATA[Hadoop 2.2.0 API CHM 版本]]></title>
    <link href="http://lsmushroom.github.io/2013/12/09/hadoop-220-api-chm-版本�/"/>
    <id>http://lsmushroom.github.io/2013/12/09/hadoop-220-api-chm-版本�/</id>
    <published>2013-12-09T06:16:29.000Z</published>
    <updated>2013-12-09T06:21:35.000Z</updated>
    <content type="html"><![CDATA[<a id="more"></a>

<p>今天从hadoop 2.2.0 版本的源码中编译生成了相应的doc文件，做成了chm文档:<a href="http://vdisk.weibo.com/s/vt7vK_plTgAz" target="_blank">hadoop-2.2.0 api.chm</a>，以后可以离线查看了</p>
<p>:)</p>
]]></content>
    <category scheme="http://lsmushroom.github.io/tags/hadoop/" term="hadoop"/>
    <category scheme="http://lsmushroom.github.io/tags/yarn/" term="yarn"/>
    <category scheme="http://lsmushroom.github.io/tags/api/" term="api"/>
    <category scheme="http://lsmushroom.github.io/tags/chm/" term="chm"/>
    <category scheme="http://lsmushroom.github.io/categories/yarn/" term="yarn"/>
  </entry>
  <entry>
    <title type="html"><![CDATA[epoll 分析总结]]></title>
    <link href="http://lsmushroom.github.io/2013/12/08/epoll-分析总结/"/>
    <id>http://lsmushroom.github.io/2013/12/08/epoll-分析总结/</id>
    <published>2013-12-08T07:23:47.000Z</published>
    <updated>2014-04-14T07:18:29.000Z</updated>
    <content type="html"><![CDATA[<h2 id="epoll_-662f-7ebf-7a0b-5b89-5168-7684-5417-ff1f-">epoll 是线程安全的吗？</h2>
<h2 id="-591a-4e2a-8fdb-7a0b-540c-65f6-6267-884c-epoll_wait-28-29-662f-5426-4f1a-89e6-53d1-60ca-7fa4-95ee-9898-ff1f-5185-6838-662f-5982-4f55-89e3-51b3-ff1f-">多个进程同时执行epoll_wait()是否会触发惊群问题？内核是如何解决？</h2>
<p>惊群问题其实是内核中早已有并有对应的应对办法的问题。对epoll而言，其关键就在以下几行代码：</p>
<p>ep_poll():</p>
<figure class="highlight"><table><tr><td class="gutter"><pre>1
2
3
4
5
6
</pre></td><td class="code"><pre>    <span class="keyword">...</span>

    init_waitqueue_entry(&wait, current);
    wait.flags |= WQ_FLAG_EXCLUSIVE;
    __add_wait_queue(&ep-&gt;wq, &wait);
    <span class="keyword">...</span>
</pre></td></tr></table></figure>

<p>以上三行代码初始化了一个等待队列entry，等待队列是linux kernel中常用的一种机制。进程请求的资源(如内存、文件等)不能得到满足时，就会主动放弃CPU，进入等待状态(可中断等待或者不可中断等待)。当资源满足时，就会由别的进程唤醒，从而投入运行。等待队列表示一组睡眠的进程，这些进程正在等待特定的事件发生(或者说条件为真)，比如，等待足够的内存。</p>
<p>其中关键之处在于WQ_FLAG_EXCLUSIVE 标志的设置。WQ_FLAG_EXCLUSIVE 意味着排他的，等待队列中将睡眠的进程划分为两种，一种即设置了WQ_FLAG_EXCLUSIVE标志的，另一种为没有设置WQ_FLAG_EXCLUSIVE标志的。当进程等待的事件发生时，尝试唤醒等待在同一事件上的所有非排他的进程，而排他的进程将只唤醒一个，由于所有睡眠的进程时挂在一个双向链表，而唤醒动作将按链表中的顺序从前往后顺序唤醒，由此对所有设置了WQ_FLAG_EXCLUSIVE的进程项将随着等待事件的发生而被逐个唤醒，而不会被全部唤醒，由此可达到两个效果，1）避免了惊群的问题，2）顺便实现了多进程/多线程对同一事件源的负载均衡，不会出现有某个进程处理过多的事件而被累死同时有的进程又处于空闲状态，在多核系统上可藉此轻松提高机器的CPU利用率。</p>
<p>相关的唤醒逻辑处理如下(还是代码更直白易懂些)：</p>
<figure class="highlight"><table><tr><td class="gutter"><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
</pre></td><td class="code"><pre>/*
* The core wakeup function. Non-exclusive wakeups (nr_exclusive == <span class="number">0</span>) just
* wake everything up. If <span class="keyword">it</span>'s an exclusive wakeup (nr_exclusive == small +ve
* <span class="type">number</span>) <span class="keyword">then</span> we wake all <span class="keyword">the</span> non-exclusive tasks <span class="keyword">and</span> one exclusive task.
*
* There are circumstances <span class="keyword">in</span> which we can <span class="keyword">try</span> <span class="keyword">to</span> wake a task which has already
* started <span class="keyword">to</span> <span class="command">run</span> <span class="keyword">but</span> <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">in</span> state TASK_RUNNING. try_to_wake_up() returns
* zero <span class="keyword">in</span> this (rare) case, <span class="keyword">and</span> we handle <span class="keyword">it</span> <span class="keyword">by</span> continuing <span class="keyword">to</span> scan <span class="keyword">the</span> queue.
*/
static void __wake_up_common(wait_queue_head_t *q, unsigned int mode,
        int nr_exclusive, int wake_flags, void *key)
{
    wait_queue_t *curr, *next;

    list_for_each_entry_safe(curr, next, &q-&gt;task_list, task_list) {
        unsigned flags = curr-&gt;flags;

        <span class="keyword">if</span> (curr-&gt;func(curr, mode, wake_flags, key) &&
                (flags & WQ_FLAG_EXCLUSIVE) && !<span class="comment">--nr_exclusive)</span>
            break;
    }
}
</pre></td></tr></table></figure>

<p>基于以上的分析，对于每一个调用epoll_wait()的进程/线程，kernel中在创建等待队列项时均设置了WQ_FLAG_EXCLUSIVE标志，由此保证了多个进程同时wait时不会有惊群问题，同时也可自动完成事件在多个进程的平均分配。</p>
]]></content>
    <category scheme="http://lsmushroom.github.io/tags/kernel/" term="kernel"/>
  </entry>
  <entry>
    <title type="html"><![CDATA[Yarn 日志级别]]></title>
    <link href="http://lsmushroom.github.io/2013/12/04/yarn日志级别调整/"/>
    <id>http://lsmushroom.github.io/2013/12/04/yarn日志级别调整/</id>
    <published>2013-12-04T09:00:06.000Z</published>
    <updated>2014-03-16T04:07:56.000Z</updated>
    <content type="html"><![CDATA[<p>Yarn 中默认的日志级别为INFO，如何调整其输出日志的级别呢？</p>
<a id="more"></a>

<p>Yarn 中提供以下命令用以查看并设置集群的输出日志级别：</p>
<figure class="highlight"><table><tr><td class="gutter"><pre>1
2
3
4
5
</pre></td><td class="code"><pre>[<span class="property">@sohu_41_173</span> ~]<span class="comment"># yarn  daemonlog</span>

<span class="attribute">Usage</span>: General options <span class="attribute">are</span>:
        [-getlevel &lt;<span class="attribute">host</span>:httpPort&gt; &lt;name&gt;]
        [-setlevel &lt;<span class="attribute">host</span>:httpPort&gt; &lt;name&gt; &lt;level&gt;]
</pre></td></tr></table></figure>

<p>使用”daemonlog”命令需要提供相应的”host:httpPort” 以及需要查看或修改日志级别的类的名称，而”host:httpPort”可以通过以下命令查询获得：</p>
<figure class="highlight"><table><tr><td class="gutter"><pre>1
2
3
4
5
6
7
</pre></td><td class="code"><pre>[<span class="property">@sohu_41_173</span> ~]<span class="comment"># yarn node  -all -list</span>
<span class="number">13</span>/<span class="number">12</span>/<span class="number">04</span> <span class="number">15</span>:<span class="number">09</span>:<span class="number">35</span> INFO client.<span class="attribute">RMProxy</span>: Connecting to ResourceManager at master.hadoop/<span class="number">10.1</span><span class="number">.41</span><span class="number">.173</span>:<span class="number">9080</span>
Total <span class="attribute">Nodes</span>:<span class="number">3</span>
     Node-Id             Node-State Node-Http-Address       Number-<span class="keyword">of</span>-Running-Containers
<span class="attribute">slave0</span>:<span class="number">54260</span>                RUNNING       <span class="attribute">slave0</span>:<span class="number">8042</span>                                  <span class="number">1</span>
<span class="attribute">slave1</span>:<span class="number">45892</span>                RUNNING       <span class="attribute">slave1</span>:<span class="number">8042</span>                                  <span class="number">2</span>
<span class="attribute">slave2</span>:<span class="number">45410</span>                RUNNING       <span class="attribute">slave2</span>:<span class="number">8042</span>                                  <span class="number">3</span>
</pre></td></tr></table></figure>

<p>以设置YarnChild.class为例：</p>
<figure class="highlight"><table><tr><td class="gutter"><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
</pre></td><td class="code"><pre>[@sohu_41_173 ~]# yarn  daemonlog -getlevel slave0:<span class="number">8042</span> YarnChild.<span class="class"><span class="keyword">class</span>
<span class="title">Connecting</span> <span class="title">to</span> <span class="title">http</span>://<span class="title">slave0</span>:8042/<span class="title">logLevel</span>?<span class="title">log</span>=<span class="title">YarnChild</span>.<span class="title">class</span>
<span class="title">Submitted</span> <span class="title">Log</span> <span class="title">Name</span>: <span class="title">YarnChild</span>.<span class="title">class</span>
<span class="title">Log</span> <span class="title">Class</span>: <span class="title">org</span>.<span class="title">apache</span>.<span class="title">commons</span>.<span class="title">logging</span>.<span class="title">impl</span>.<span class="title">Log4JLogger</span>
<span class="title">Effective</span> <span class="title">level</span>: <span class="title">INFO</span>
[@<span class="title">sohu_41_173</span> ~]# <span class="title">yarn</span>  <span class="title">daemonlog</span> -<span class="title">setlevel</span> <span class="title">slave0</span>:8042 <span class="title">YarnChild</span>.<span class="title">class</span> <span class="title">DEBUG</span>
<span class="title">Connecting</span> <span class="title">to</span> <span class="title">http</span>://<span class="title">slave0</span>:8042/<span class="title">logLevel</span>?<span class="title">log</span>=<span class="title">YarnChild</span>.<span class="title">class</span>&<span class="title">level</span>=<span class="title">DEBUG</span>
<span class="title">Submitted</span> <span class="title">Log</span> <span class="title">Name</span>: <span class="title">YarnChild</span>.<span class="title">class</span>
<span class="title">Log</span> <span class="title">Class</span>: <span class="title">org</span>.<span class="title">apache</span>.<span class="title">commons</span>.<span class="title">logging</span>.<span class="title">impl</span>.<span class="title">Log4JLogger</span>
<span class="title">Submitted</span> <span class="title">Level</span>: <span class="title">DEBUG</span>
<span class="title">Setting</span> <span class="title">Level</span> <span class="title">to</span> <span class="title">DEBUG</span> ...
<span class="title">Effective</span> <span class="title">level</span>: <span class="title">DEBUG</span>
[@<span class="title">sohu_41_173</span> ~]# <span class="title">yarn</span>  <span class="title">daemonlog</span> -<span class="title">getlevel</span> <span class="title">slave0</span>:8042 <span class="title">YarnChild</span>.<span class="title">class</span>
<span class="title">Connecting</span> <span class="title">to</span> <span class="title">http</span>://<span class="title">slave0</span>:8042/<span class="title">logLevel</span>?<span class="title">log</span>=<span class="title">YarnChild</span>.<span class="title">class</span>
<span class="title">Submitted</span> <span class="title">Log</span> <span class="title">Name</span>: <span class="title">YarnChild</span>.<span class="title">class</span>
<span class="title">Log</span> <span class="title">Class</span>: <span class="title">org</span>.<span class="title">apache</span>.<span class="title">commons</span>.<span class="title">logging</span>.<span class="title">impl</span>.<span class="title">Log4JLogger</span>
<span class="title">Effective</span> <span class="title">level</span>: <span class="title">DEBUG</span></span>
</pre></td></tr></table></figure>

<p>Done. :)</p>
]]></content>
    <category scheme="http://lsmushroom.github.io/tags/yarn/" term="yarn"/>
    <category scheme="http://lsmushroom.github.io/tags/hadoop/" term="hadoop"/>
    <category scheme="http://lsmushroom.github.io/categories/yarn/" term="yarn"/>
  </entry>
  <entry>
    <title type="html"><![CDATA[Pig on Yarn]]></title>
    <link href="http://lsmushroom.github.io/2013/11/28/pig-on-yarn/"/>
    <id>http://lsmushroom.github.io/2013/11/28/pig-on-yarn/</id>
    <published>2013-11-28T06:52:38.000Z</published>
    <updated>2013-11-29T14:22:06.000Z</updated>
    <content type="html"><![CDATA[<p>今天尝试了下将pig部署到hadoop2.2.0版的集群上，过程相对较顺利，简单记录下。</p>
<a id="more"></a>

<h2 id="-90e8-7f72-">部署</h2>
<p>部署需要依赖ant编译工具，当前使用版本为<a href="http://archive.apache.org/dist/ant/binaries/apache-ant-1.7.1-bin.zip" target="_blank">apache-ant-1.7.1</a><br>下载 pig 最新版源码包 pig-0.12.0-src,解压后对其进行编译,当前pig适配于hadoop20与hadoop23版本，因我们需要将其部署在Yarn平台上，选取适配的目标版本为hadoop23</p>
<pre><code><span class="comment">ant</span> <span class="comment">clean</span> <span class="comment">jar</span><span class="literal">-</span><span class="comment">withouthadoop</span> <span class="literal">-</span><span class="comment">Dhadoopversion=23</span>
</code></pre><p>编译过程将下载依赖的包，比较慢。 编译完成后添加pig脚本所处的目录至 $PATH 环境变量中即完成了pig的部署。</p>
<h2 id="-6d4b-8bd5-">测试</h2>
<p>Pig-Latin 实现的wordcount:</p>
<pre><code>A = load <span class="comment">'./input.txt';</span>
B = foreach A generate flatten(TOKENIZE((chararray)$<span class="number">0</span>)) <span class="keyword">as</span> word;
C = <span class="keyword">group</span> B <span class="keyword">by</span> word;
D = foreach C generate COUNT(B), <span class="keyword">group</span>;
store D <span class="keyword">into</span> <span class="comment">'./wordcount';</span>
</code></pre><p>运行wordcout测试程序：</p>
<pre><code><span class="comment">#将输入文件上传至HDFS</span>
[<span class="variable">@sohu_41_173</span> pig-wordcount]<span class="comment">#hdfs dfs -put ./input.txt input.txt</span>

<span class="comment">#执行wordcount.pig脚本</span>
[<span class="variable">@sohu_41_173</span> pig-wordcount]<span class="comment"># pig ./wordcount.pig</span>

<span class="comment">#检查输出</span>
[<span class="variable">@sohu_41_173</span> pig-wordcount]<span class="comment"># hdfs dfs -cat wordcount/part-r-00000</span>
</code></pre><p>完成 :)</p>
]]></content>
    <category scheme="http://lsmushroom.github.io/tags/pig/" term="pig"/>
    <category scheme="http://lsmushroom.github.io/tags/yarn/" term="yarn"/>
    <category scheme="http://lsmushroom.github.io/tags/hadoop/" term="hadoop"/>
    <category scheme="http://lsmushroom.github.io/categories/yarn/" term="yarn"/>
  </entry>
  <entry>
    <title type="html"><![CDATA[Cgroup Test]]></title>
    <link href="http://lsmushroom.github.io/2013/11/21/cgroup-test/"/>
    <id>http://lsmushroom.github.io/2013/11/21/cgroup-test/</id>
    <published>2013-11-21T03:55:25.000Z</published>
    <updated>2014-03-16T04:01:24.000Z</updated>
    <content type="html"><![CDATA[<a id="more"></a>

<h1 id="Cgroup_Subsystem">Cgroup Subsystem</h1>
<hr>
<h2 id="CPU_Subsystem">CPU Subsystem</h2>
<p>创建三个cgroup，对前两组设定cpu.shares比例为1:2 ，对第三组不设定cpu.shares参数，三个cgroup内运行的进程均被限制仅能在0号核上运行，可访问内存结点为0,1</p>
<pre><code>[@sohu_41_173 ~]<span class="preprocessor"># cat /etc/cgconfig.conf</span>
mount {
    cpu     = /cgroup/cpu<span class="comment">;</span>
    cpuset  = /cgroup/cpuset<span class="comment">;</span>
    memory  = /cgroup/memory<span class="comment">;</span>
}

group test1 {
    cpuset{
        cpuset<span class="preprocessor">.cpus</span>=<span class="string">"0"</span><span class="comment">;</span>
        cpuset<span class="preprocessor">.mems</span>=<span class="string">"0,1"</span><span class="comment">;</span>
    }
    cpu{
        cpu<span class="preprocessor">.shares</span>=<span class="string">"100"</span><span class="comment">;</span>
    }
}
group test2 {
    cpuset{
        cpuset<span class="preprocessor">.cpus</span>=<span class="string">"0"</span><span class="comment">;</span>
        cpuset<span class="preprocessor">.mems</span>=<span class="string">"0,1"</span><span class="comment">;</span>
    }
    cpu{
        cpu<span class="preprocessor">.shares</span>=<span class="string">"200"</span><span class="comment">;</span>
    }
}

group test3 {
    cpuset{
        cpuset<span class="preprocessor">.cpus</span>=<span class="string">"0"</span><span class="comment">;</span>
        cpuset<span class="preprocessor">.mems</span>=<span class="string">"0,1"</span><span class="comment">;</span>
    }
}
</code></pre><p>设定cgrules.conf 如下，使用C实现的简易的压测工具stress，其被编译成单独的可执行程序，简单的复制并重命名2份供另两组使用，在启动时将由cgrulesengd自动与配置的cgroup绑定运行，受相应的subsystem控制</p>
<pre><code>[<span class="variable">@sohu_41_173</span> ~]<span class="comment"># cat /etc/cgrules.conf</span>
*<span class="symbol">:/usr/local/bin/stress</span>         cpu,cpuset              /test1
*<span class="symbol">:/usr/local/bin/stress2</span>        cpu,cpuset              /test2
*<span class="symbol">:/usr/local/bin/stress3</span>        cpuset                  /test3
</code></pre><p><em>测试一</em></p>
<pre><code>[<span class="variable">@sohu_41_173</span> ~]<span class="comment"># stress -c 1</span>
stress: info: [<span class="number">48624</span>] dispatching hogs: <span class="number">1</span> cpu, <span class="number">0</span> io, <span class="number">0</span> vm, <span class="number">0</span> hdd

[<span class="variable">@sohu_41_173</span> ~]<span class="comment"># stress2 -c 1</span>
stress2: info: [<span class="number">48632</span>] dispatching hogs: <span class="number">1</span> cpu, <span class="number">0</span> io, <span class="number">0</span> vm, <span class="number">0</span> hdd

[<span class="variable">@sohu_41_173</span> ~]<span class="comment"># top -p 48633,48625 -b</span>
top - <span class="number">12</span>:08:<span class="number">04</span> up <span class="number">9</span> days, <span class="number">16</span>:<span class="number">32</span>,  <span class="number">7</span> users,  load average: <span class="number">1.94</span>, <span class="number">1.19</span>, <span class="number">2.09</span>
Tasks:   <span class="number">2</span> total,   <span class="number">2</span> running,   <span class="number">0</span> sleeping,   <span class="number">0</span> stopped,   <span class="number">0</span> zombie
Cpu(<span class="keyword">s</span>):  <span class="number">0</span>.<span class="number">2</span><span class="variable">%us</span>,  <span class="number">0</span>.<span class="number">1</span><span class="variable">%sy</span>,  <span class="number">0</span>.<span class="number">0</span><span class="variable">%ni</span>, <span class="number">99.7</span><span class="variable">%id</span>,  <span class="number">0</span>.<span class="number">0</span><span class="variable">%wa</span>,  <span class="number">0</span>.<span class="number">0</span><span class="variable">%hi</span>,  <span class="number">0</span>.<span class="number">0</span><span class="variable">%si</span>,  <span class="number">0</span>.<span class="number">0</span><span class="variable">%st</span>
Mem:  <span class="number">65820492</span>k total, <span class="number">30009200</span>k used, <span class="number">35811292</span>k free,  <span class="number">1110200</span>k buffers
Swap:  <span class="number">4194296</span>k total,        0k used,  <span class="number">4194296</span>k free,  <span class="number">9438732</span>k cached

PID USER      PR  NI  VIRT  RES  SHR S <span class="variable">%CPU</span> <span class="variable">%MEM</span>    TIME+  COMMAND
<span class="number">48633</span> root      <span class="number">20</span>   <span class="number">0</span>  <span class="number">6516</span>  <span class="number">192</span>  <span class="number">104</span> R <span class="number">67.8</span>  <span class="number">0</span>.<span class="number">0</span>   <span class="number">1</span>:<span class="number">23.57</span> stress2
<span class="number">48625</span> root      <span class="number">20</span>   <span class="number">0</span>  <span class="number">6516</span>  <span class="number">192</span>  <span class="number">104</span> R <span class="number">33.9</span>  <span class="number">0</span>.<span class="number">0</span>   <span class="number">0</span>:<span class="number">47.31</span> stress
</code></pre><p>运行stress和stress2，两个程序分别受test和test1 cpu和cpuset子系统控制，从%CPU可看出，当两个进程被限制在同一个CPU核上运行时，其占用CPU的比例符合cpu.shares所配置的1:2的比例</p>
<p><em>测试二</em><br>修改三个cgroup组cpuset配置如下：</p>
<pre><code>cpuset<span class="preprocessor">.cpus</span>=<span class="string">"0,2"</span><span class="comment">;</span>
</code></pre><p>限制三个组内运行的进程可使用的CPU核为0和2号核，重启服务以使配置生效</p>
<pre><code>[<span class="property">@sohu_41_173</span> ~]<span class="comment"># /etc/init.d/cgconfig restart</span>
Stopping cgconfig <span class="attribute">service</span>:                                 [  OK  ]
Starting cgconfig <span class="attribute">service</span>:                                 [  OK  ]
[<span class="property">@sohu_41_173</span> ~]<span class="comment"># /etc/init.d/cgred restart</span>
Stopping CGroup Rules Engine Daemon...                     [  OK  ]
Starting CGroup Rules Engine <span class="attribute">Daemon</span>:                       [  OK  ]
</code></pre><p><em>测试三</em><br>添加test3 cgroup 用以测试memory cgroup的功能:</p>
<pre><code>group test3 {
    cpuset{
        cpuset<span class="preprocessor">.cpus</span>=<span class="string">"0"</span><span class="comment">;</span>
        cpuset<span class="preprocessor">.mems</span>=<span class="string">"0,1"</span><span class="comment">;</span>
    }
    memory{
        memory<span class="preprocessor">.limit</span>_in_bytes=<span class="number">50</span>m<span class="comment">;</span>
        memory<span class="preprocessor">.memsw</span><span class="preprocessor">.limit</span>_in_bytes = <span class="number">50</span>m<span class="comment">;</span>
    }
}

cat /etc/cgrules<span class="preprocessor">.conf</span>
*:/usr/local/bin/stress3        cpuset,memory                  /test3
</code></pre><p>其中memory.limit_in_bytes用以控制组内可使用的用户态内存（包括文件缓存），有效值的可为数字加单位后缀：k/K,m/M,g/G, 未明确给出单位的默认为字节，-1表示没有内存限制。不可通过此项来限制根cgroup的内存使用量。</p>
<p>memory.memsw.limit_in_bytes 用以控制内存与swap分区的使用总量，如此项为显示的配置，则当达到memory.limit_in_bytes使用上限时，将开始消耗全局系统的swap分区，直至消耗尽全局系统的所有swap空间，进而因没有swap空间而触发OOM。配置方法同memory.limit_in_bytes，但要求在提供有效的memory.limit_in_bytes值后方可配置memory.memsw.limit_in_bytes，即使在/etc/cgconfig.conf中亦应保证memory.limit_in_bytes在前，否则配置失败。</p>
]]></content>
  </entry>
  <entry>
    <title type="html"><![CDATA[vim Macro]]></title>
    <link href="http://lsmushroom.github.io/2013/11/19/vim-macro/"/>
    <id>http://lsmushroom.github.io/2013/11/19/vim-macro/</id>
    <published>2013-11-18T16:01:03.000Z</published>
    <updated>2013-11-29T14:21:51.000Z</updated>
    <content type="html"><![CDATA[<p>vim 宏提供一种将一系列的操作批量应用于多行内容上的功能<br><a id="more"></a></p>
<h2 id="-8bb0-5f55-5b8f-3a-">记录宏:</h2>
<pre><code><span class="comment">visual</span> <span class="comment">模式下q</span><span class="literal">+</span><span class="comment">'</span><span class="title">[</span><span class="comment">a</span><span class="literal">-</span><span class="comment">z</span><span class="title">]</span><span class="comment">'</span><span class="string">,</span><span class="comment">q加任意一个字母按键即开始进入宏记录模式，所记录的操作后续可使用字母引用。</span>
<span class="comment">随后进入编辑模式，输入一系列的命令，在完成输入后再按q即可完成记录</span><span class="string">,</span><span class="comment">记录被保存。</span>
</code></pre><h2 id="-5e94-7528-5b8f-ff1a-">应用宏：</h2>
<pre><code><span class="comment">@</span><span class="title">[</span><span class="comment">a</span><span class="literal">-</span><span class="comment">z</span><span class="title">]</span><span class="comment">:@</span><span class="literal">+</span><span class="comment">之前宏对应的字母即可将宏操作应用于新的记录上</span>
</code></pre><h2 id="-5347-7ea7-7248-ff1a-">升级版：</h2>
<pre><code>在.vimrc中添加以下内容，即可将<span class="variable">@q</span>操作映射为空格键。
由此在记录宏时可按如下步骤进行：
开始记录：qq
结束记录：q
应用宏：敲空格键
</code></pre><h2 id="-5c06-5b8f-5e94-7528-5728-591a-884c-4e0a-ff1a-">将宏应用在多行上：</h2>
<pre><code>可在<span class="constant">VISUAL</span>模式下选定多行，然后输入<span class="symbol">:normal</span> <span class="variable">@q</span>,即可将宏同时作用于多行
</code></pre><h2 id="-5b8f-7684-wiki">宏的wiki</h2>
<pre><code>&lt;http://vim<span class="preprocessor">.wikia</span><span class="preprocessor">.com</span>/wiki/Macros&gt;
</code></pre>]]></content>
    <category scheme="http://lsmushroom.github.io/tags/vim/" term="vim"/>
    <category scheme="http://lsmushroom.github.io/categories/vim/" term="vim"/>
  </entry>
  <entry>
    <title type="html"><![CDATA[deploy hexo on RHEL6]]></title>
    <link href="http://lsmushroom.github.io/2013/11/18/deploy-hexo-on-rhel6/"/>
    <id>http://lsmushroom.github.io/2013/11/18/deploy-hexo-on-rhel6/</id>
    <published>2013-11-18T15:07:42.000Z</published>
    <updated>2013-12-23T07:26:43.000Z</updated>
    <content type="html"><![CDATA[<p>基于RHEL6成功部署了hexo，博客落户github了，记录下部署的过程<br><a id="more"></a></p>
<h1 id="1-_-5b89-88c5-">1. 安装</h1>
<p>hexo环境的部署将被安装至用户目录下的.nvm等目录中，故root用户安装后非root用户将因权限问题而无法使用</p>
<h2 id="1-_-4e0b-8f7d-76f8-5173-5e93-">1. 下载相关库</h2>
<pre><code>curl https://raw<span class="preprocessor">.github</span><span class="preprocessor">.com</span>/creationix/nvm/master/install<span class="preprocessor">.sh</span> | sh
完成后nvm即安装完毕，但需要断开终端重连后nvm可生效
</code></pre><h2 id="2-_-5b89-88c5-Node-js">2. 安装Node.js</h2>
<pre><code><span class="title">nvm</span> install <span class="number">0.10</span>
</code></pre><h2 id="3-_-5b89-88c5-Hexo">3. 安装Hexo</h2>
<pre><code><span class="comment">npm</span> <span class="comment">install</span> <span class="literal">-</span><span class="comment">g</span> <span class="comment">hexo</span>
</code></pre><h2 id="4-_-6dfb-52a0-76f8-5173-7684-73af-5883-53d8-91cf-81f3-bashrc-4e2d-">4. 添加相关的环境变量至.bashrc中</h2>
<pre><code><span class="keyword">export</span> PATH=~/.nvm/v0.<span class="number">10.24</span>/bin/:<span class="variable">$PATH</span>
</code></pre><h1 id="2-_-4f7f-7528-">2. 使用</h1>
<h2 id="2-1_-521d-59cb-5316-76ee-5f55-">2.1    初始化目录</h2>
<pre><code><span class="title">hexo</span> init
</code></pre><h2 id="2-2_-521b-5efa-65b0-7684-Post">2.2    创建新的Post</h2>
<pre><code>hexo <span class="keyword">new</span> <span class="string">"My First Post"</span>
</code></pre><h2 id="2-3_-7531-markdown-6587-4ef6-751f-6210-9759-6001-html-6587-4ef6-">2.3    由markdown文件生成静态html文件</h2>
<pre><code><span class="title">hexo</span> generate
</code></pre><h2 id="2-4_-672c-5730-9884-89c8-">2.4    本地预览</h2>
<pre><code>hexo <span class="keyword">server</span>
随后即可在浏览器中预览，对应的地址为服务器的ip,默认的端口为<span class="number">4000</span>。也可通过hexo <span class="keyword">server</span> -p 选项指定监听的端口
&lt;example: <span class="number">10.1</span><span class="number">.41</span><span class="number">.173</span>:<span class="number">4000</span>
</code></pre><h2 id="2-5_-5c06-672c-5730-blog-90e8-7f72-81f3-github-5bf9-5e94-7684-4ed3-5e93-4e0a-">2.5    将本地blog部署至github对应的仓库上</h2>
<pre><code><span class="number">1</span>）编辑blog根目录下的_config<span class="preprocessor">.yml</span>，指定博客将被部署至哪
    <span class="preprocessor"># Deployment</span>
    <span class="preprocessor">## Docs: http://zespia.tw/hexo/docs/deploy.html</span>
    deploy:
      type: github  <span class="preprocessor">#指定待部署的空间的类型，当前要将blog部署至github上在此填github即可</span>
      repository: git@github<span class="preprocessor">.com</span>:lsmushroom/lsmushroom<span class="preprocessor">.github</span><span class="preprocessor">.io</span><span class="preprocessor">.git</span>  <span class="preprocessor">#给出仓库的链接</span>

<span class="number">2</span>）hexo deploy

至此已通过hexo成功部署一个基本的blog，后续即需了解如何写
</code></pre><h1 id="3-_-5199-blog">3. 写blog</h1>
<pre><code><span class="comment">3</span><span class="string">.</span><span class="comment">1</span> <span class="comment">hexo对中文输入的支持</span>
    <span class="comment">hexo要求</span><span class="string">.</span><span class="comment">md文件为utf</span><span class="literal">-</span><span class="comment">8编码，故需对文件做一些设置：</span>
<span class="comment">3</span><span class="string">.</span><span class="comment">2</span> <span class="comment">markdown语法</span>
</code></pre>]]></content>
    <category scheme="http://lsmushroom.github.io/tags/hexo/" term="hexo"/>
    <category scheme="http://lsmushroom.github.io/categories/yarn/" term="yarn"/>
  </entry>
  <entry>
    <title type="html"><![CDATA[accept 惊群问题]]></title>
    <link href="http://lsmushroom.github.io/2013/04/15/accept-惊群问题/"/>
    <id>http://lsmushroom.github.io/2013/04/15/accept-惊群问题/</id>
    <published>2013-04-15T14:15:28.000Z</published>
    <updated>2014-04-15T15:36:25.000Z</updated>
    <content type="html"><![CDATA[<p>Unix 网络编程上有一章中曾对多种网络编程模型做了个对比， 其中一种典型的网络编程模型为预先创建一进程池，在父进程中listen，各个子进程同时执行accept()同一个listenfd，且无锁互斥。</p>
<p>书中谈到多个进程同时accept()同一个listenfd，当有可用的连接而至accept()返回时，不会产生惊群现象。对此十分好奇，翻看下listen() 与 accept()相关的系统调用内核源码查个原委。</p>
<a id="more"></a>

<p>accept()是由glibc提供的，应用程序中所使用socket api最终均是通过socketcall实现统一的系统调用:</p>
<figure class="highlight"><table><tr><td class="gutter"><pre>1
2
3
4
5
6
7
8
9
10
</pre></td><td class="code"><pre>man <span class="number">2</span> socketcall

<span class="variable">SYNOPSIS</span>
int socketcall(int call, unsigned long *args);

<span class="variable">DESCRIPTION</span>
<span class="function"><span class="title">socketcall</span><span class="params">()</span>  <span class="title">is</span>  <span class="title">a</span> <span class="title">common</span> <span class="title">kernel</span> <span class="title">entry</span> <span class="title">point</span> <span class="title">for</span> <span class="title">the</span> <span class="title">socket</span> <span class="title">system</span> <span class="title">calls</span>.  <span class="title">call</span> <span class="title">determines</span> <span class="title">which</span> <span class="title">socket</span> <span class="title">function</span> <span class="title">to</span> <span class="title">invoke</span>.  <span class="title">args</span> <span class="title">points</span> <span class="title">to</span> <span class="title">a</span> <span class="title">block</span> <span class="title">containing</span> <span class="title">the</span> <span class="title">actual</span> <span class="title">arguments</span>, <span class="title">which</span> <span class="title">are</span> <span class="title">passed</span> <span class="title">through</span> <span class="title">to</span>  <span class="title">the</span>  <span class="title">appropriate</span> <span class="title">call</span>.

U<span class="title">ser</span> <span class="title">programs</span> <span class="title">should</span> <span class="title">call</span> <span class="title">the</span> <span class="title">appropriate</span> <span class="title">functions</span> <span class="title">by</span> <span class="title">their</span> <span class="title">usual</span> <span class="title">names</span>.  O<span class="title">nly</span> <span class="title">standard</span> <span class="title">library</span> <span class="title">implementors</span> <span class="title">and</span>
<span class="title">kernel</span> <span class="title">hackers</span> <span class="title">need</span> <span class="title">to</span> <span class="title">know</span> <span class="title">about</span> <span class="title">socketcall</span><span class="params">()</span>.</span>
</pre></td></tr></table></figure>

<p>Kernel中通过用户态传入的系统调用号调用相关的系统调用，对listen() 与 accept() 将分别调用 sys_listen() 和 sys_accept4()</p>
<p>对accept() 而言，其将从listen系统调用接受的连接的队列中(struct inet_connection_sock-&gt;isck_accept_queue.listen_sock-&gt;syn_table)取一个连接，并建立一个新的socket，把这个连接(struct request_sock)赋给这个新的sokcet，此后，该连接就由这个新的socket负责与对端进行通讯。</p>
<p>inet_csk_accept()函数中将首先检查等待连接的队列是否为空，若为空则表示当前还没有收到顺利经过三次握手而建立的连接请求，若已经加listenfd设置O_NONBLOCK 非阻塞标志，则将立即返回并将errno设置为-EAGAIN，否则将调用inet_csk_wait_for_connect()。</p>
<p>inet_csk_wait_for_connect()将完成accept()的阻塞等待，其核心是通过定义一等待队列项，将当前调用accept()系统调用的进程挂至listernfd 的sk-&gt;sk_sleep等待队列上，当有完成三次握手而成功建立的连接时将尝试唤醒挂在此等待队列上的进程。当有多个进程同时accept()同一个listenfd时，亦即有多个进程同时挂载同一listenfd的sk-&gt;sk_sleep等待队列上时，唤醒时将仅唤醒一个，未被唤醒的将继续睡眠等待下一次事件的到来，多个等待的进程将依次顺序被唤醒，而保证这一点的关键为inet_csk_wait_for_connect()中创建的等待队列项设置了WQ_FLAG_EXCLUSIVE标志项，kernel中的等待队列机制将保证对所有设置了WQ_FLAG_EXCLUSIVE标志的等待队列项，等待的同一事件发生时将仅唤醒一个进程。</p>
<p>由此用户态代码可放心的起多个进程同时accept() ,内核可保证各个连接均能被进程正确的处理且事件将被均匀的分发至各个进程处理。</p>
<p>Done. :)</p>
]]></content>
    <category scheme="http://lsmushroom.github.io/tags/kernel/" term="kernel"/>
  </entry>
</feed>
